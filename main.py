#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Telegramå›¾åºŠæœºå™¨äºº - äº‘å­˜å‚¨ç‰ˆ (ç®€åŒ–ç‰ˆï¼Œæ— ç»Ÿè®¡ç³»ç»Ÿ)
æ”¯æŒè‡ªå®šä¹‰CDNåŸŸåã€æ™ºèƒ½è·¯ç”±ã€ç¼“å­˜é¢„çƒ­ç­‰é«˜çº§åŠŸèƒ½
åç«¯CDNç¼“å­˜ç›‘æ§ç‰ˆæœ¬ - ä¿®å¤é‡å®šå‘å¾ªç¯å’Œæ–‡ä»¶è·¯å¾„è¿‡æœŸé—®é¢˜
æ–°å¢ç¾¤ç»„å›¾ç‰‡ç›‘å¬åŠŸèƒ½
"""
import logging
import hashlib
import time
import asyncio
import base64
import socket
import json
import os
import threading
import sqlite3
import sys
import atexit
import queue
import subprocess
import shutil
import signal
from pathlib import Path
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass  # python-dotenv æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿç¯å¢ƒå˜é‡

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from flask import Flask, render_template, jsonify, request, Response, send_file, make_response, redirect
from flask_cors import CORS
from werkzeug.middleware.proxy_fix import ProxyFix
import aiohttp
import requests

# å¯¼å…¥ç®¡ç†æ¨¡å—
import admin_module

# ===================== é…ç½®å‚æ•° (æ”¯æŒç¯å¢ƒå˜é‡) =====================
BOT_TOKEN = os.getenv("BOT_TOKEN", "")
STORAGE_CHAT_ID = int(os.getenv("STORAGE_CHAT_ID", ""))
SECRET_KEY = os.getenv("SECRET_KEY", "your_secret_key_2024")
PORT = int(os.getenv("PORT", "18793"))

# å‰ç«¯è‡ªåŠ¨å¯åŠ¨é…ç½®
FRONTEND_AUTOSTART = os.getenv("FRONTEND_AUTOSTART", "true").lower() == "true"
FRONTEND_DIR = os.path.join(os.getcwd(), "frontend")
FRONTEND_PORT = int(os.getenv("FRONTEND_PORT", "3000"))
# å¯è‡ªå®šä¹‰å‘½ä»¤ï¼Œå¦‚: "pnpm dev" æˆ– "yarn dev"
FRONTEND_DEV_CMD = os.getenv("FRONTEND_DEV_CMD", "npm run dev")

# ç¾¤ç»„ä¸Šä¼ åŠŸèƒ½é…ç½®
ENABLE_GROUP_UPLOAD = os.getenv("ENABLE_GROUP_UPLOAD", "true").lower() == "true"
GROUP_UPLOAD_ADMIN_ONLY = os.getenv("GROUP_UPLOAD_ADMIN_ONLY", "false").lower() == "true"
GROUP_ADMIN_IDS = os.getenv("GROUP_ADMIN_IDS", "")  # é€—å·åˆ†éš”çš„ç®¡ç†å‘˜IDåˆ—è¡¨
GROUP_UPLOAD_REPLY = os.getenv("GROUP_UPLOAD_REPLY", "true").lower() == "true"  # æ˜¯å¦å›å¤æ¶ˆæ¯
GROUP_UPLOAD_DELETE_DELAY = int(os.getenv("GROUP_UPLOAD_DELETE_DELAY", "0"))  # åˆ é™¤å›å¤çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºä¸åˆ é™¤

# CDN ç›¸å…³é…ç½®
CDN_ENABLED = os.getenv("CDN_ENABLED", "true").lower() == "true"
CDN_CACHE_TTL = int(os.getenv("CDN_CACHE_TTL", "31536000"))  # é»˜è®¤ä¸€å¹´
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "*")

# CDNé‡å®šå‘é…ç½®ï¼ˆæ–°å¢ï¼‰
CDN_REDIRECT_ENABLED = os.getenv("CDN_REDIRECT_ENABLED", "true").lower() == "true"  # æ˜¯å¦å¯ç”¨CDNé‡å®šå‘
CDN_REDIRECT_MAX_COUNT = int(os.getenv("CDN_REDIRECT_MAX_COUNT", "2"))  # æœ€å¤§é‡å®šå‘æ¬¡æ•°
CDN_REDIRECT_CACHE_TIME = int(os.getenv("CDN_REDIRECT_CACHE_TIME", "300"))  # é‡å®šå‘ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰
CDN_REDIRECT_DELAY = int(os.getenv("CDN_REDIRECT_DELAY", "10"))  # æ–°ä¸Šä¼ æ–‡ä»¶å»¶è¿Ÿé‡å®šå‘æ—¶é—´ï¼ˆç§’ï¼‰

# Cloudflare CDN ç‰¹å®šé…ç½®
CLOUDFLARE_CDN_DOMAIN = os.getenv("CLOUDFLARE_CDN_DOMAIN", "")
CLOUDFLARE_API_TOKEN = os.getenv("CLOUDFLARE_API_TOKEN", "")
CLOUDFLARE_ZONE_ID = os.getenv("CLOUDFLARE_ZONE_ID", "")
CLOUDFLARE_CACHE_LEVEL = os.getenv("CLOUDFLARE_CACHE_LEVEL", "aggressive")
CLOUDFLARE_BROWSER_TTL = int(os.getenv("CLOUDFLARE_BROWSER_TTL", "14400"))
CLOUDFLARE_EDGE_TTL = int(os.getenv("CLOUDFLARE_EDGE_TTL", "2592000"))

# æ™ºèƒ½è·¯ç”±é…ç½®
ENABLE_SMART_ROUTING = os.getenv("ENABLE_SMART_ROUTING", "true").lower() == "true"
FALLBACK_TO_ORIGIN = os.getenv("FALLBACK_TO_ORIGIN", "true").lower() == "true"

# ç¼“å­˜é¢„çƒ­é…ç½®
ENABLE_CACHE_WARMING = os.getenv("ENABLE_CACHE_WARMING", "true").lower() == "true"
CACHE_WARMING_DELAY = int(os.getenv("CACHE_WARMING_DELAY", "5"))

# CDNç¼“å­˜ç›‘æ§é…ç½®
CDN_MONITOR_ENABLED = os.getenv("CDN_MONITOR_ENABLED", "true").lower() == "true"
CDN_MONITOR_INTERVAL = int(os.getenv("CDN_MONITOR_INTERVAL", "5"))  # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
CDN_MONITOR_MAX_RETRIES = int(os.getenv("CDN_MONITOR_MAX_RETRIES", "15"))  # æœ€å¤§é‡è¯•æ¬¡æ•°
CDN_MONITOR_QUEUE_SIZE = int(os.getenv("CDN_MONITOR_QUEUE_SIZE", "1000"))  # é˜Ÿåˆ—å¤§å°

# ç‰ˆæœ¬æ§åˆ¶
STATIC_VERSION = os.getenv("STATIC_VERSION", str(int(time.time())))
FORCE_REFRESH = os.getenv("FORCE_REFRESH", "false").lower() == "true"

# æ•°æ®åº“è·¯å¾„
DEFAULT_DB_PATH = os.path.join(os.getcwd(), "telegram_imagebed.db")
DATABASE_PATH = os.getenv("DATABASE_PATH", DEFAULT_DB_PATH)

# ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
db_dir = os.path.dirname(DATABASE_PATH)
if db_dir and not os.path.exists(db_dir):
    os.makedirs(db_dir, exist_ok=True)

# æ—¥å¿—é…ç½®
LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
LOG_FILE = os.getenv("LOG_FILE", "telegram_imagebed.log")

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', 
    level=getattr(logging, LOG_LEVEL.upper()),
    handlers=[
        logging.FileHandler(LOG_FILE),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å•å®ä¾‹é”æ–‡ä»¶
if sys.platform == 'win32':
    LOCK_FILE = os.path.join(os.environ.get('TEMP', '.'), 'telegram_imagebed.lock')
else:
    LOCK_FILE = '/tmp/telegram_imagebed.lock'

# æ‰“å°é…ç½®ä¿¡æ¯
logger.info("=" * 60)
logger.info("Telegram å›¾åºŠæœºå™¨äºº - ç®€åŒ–ç‰ˆï¼ˆåç«¯CDNç›‘æ§ï¼‰")
logger.info("=" * 60)
logger.info(f"BOT_TOKEN: {'å·²é…ç½®' if BOT_TOKEN else 'æœªé…ç½®'}")
logger.info(f"STORAGE_CHAT_ID: {STORAGE_CHAT_ID}")
logger.info(f"PORT: {PORT}")
logger.info(f"DATABASE_PATH: {DATABASE_PATH}")
logger.info(f"CDN_ENABLED: {CDN_ENABLED}")
logger.info(f"ç¾¤ç»„ä¸Šä¼ åŠŸèƒ½: {ENABLE_GROUP_UPLOAD}")
if ENABLE_GROUP_UPLOAD:
    logger.info(f"ä»…ç®¡ç†å‘˜: {GROUP_UPLOAD_ADMIN_ONLY}")
    logger.info(f"ç®¡ç†å‘˜ID: {GROUP_ADMIN_IDS or 'æœªé…ç½®'}")
    logger.info(f"å›å¤æ¶ˆæ¯: {GROUP_UPLOAD_REPLY}")
if CDN_ENABLED:
    logger.info(f"CLOUDFLARE_CDN_DOMAIN: {CLOUDFLARE_CDN_DOMAIN or 'æœªé…ç½®'}")
    logger.info(f"æ™ºèƒ½è·¯ç”±: {ENABLE_SMART_ROUTING}")
    logger.info(f"ç¼“å­˜é¢„çƒ­: {ENABLE_CACHE_WARMING}")
    logger.info(f"CDNç›‘æ§: {CDN_MONITOR_ENABLED}")
    logger.info(f"CDNé‡å®šå‘: {CDN_REDIRECT_ENABLED}")
    logger.info(f"æœ€å¤§é‡å®šå‘æ¬¡æ•°: {CDN_REDIRECT_MAX_COUNT}")
    logger.info(f"æ–°æ–‡ä»¶é‡å®šå‘å»¶è¿Ÿ: {CDN_REDIRECT_DELAY}ç§’")
logger.info("=" * 60)

# è§£æç®¡ç†å‘˜IDåˆ—è¡¨
GROUP_ADMIN_ID_LIST = []
if GROUP_ADMIN_IDS:
    try:
        GROUP_ADMIN_ID_LIST = [int(id.strip()) for id in GROUP_ADMIN_IDS.split(',') if id.strip()]
        logger.info(f"å·²é…ç½® {len(GROUP_ADMIN_ID_LIST)} ä¸ªç¾¤ç»„ç®¡ç†å‘˜ID")
    except Exception as e:
        logger.error(f"è§£æç®¡ç†å‘˜IDåˆ—è¡¨å¤±è´¥: {e}")

# ===================== å•å®ä¾‹é” =====================
def acquire_lock():
    """è·å–é”ä»¥ç¡®ä¿åªæœ‰ä¸€ä¸ªå®ä¾‹åœ¨è¿è¡Œ"""
    try:
        if sys.platform == 'win32':
            import msvcrt
            global lock_file_handle
            lock_file_handle = open(LOCK_FILE, 'w')
            try:
                msvcrt.locking(lock_file_handle.fileno(), msvcrt.LK_NBLCK, 1)
                return True
            except IOError:
                logger.error("å¦ä¸€ä¸ªå®ä¾‹æ­£åœ¨è¿è¡Œ")
                return False
        else:
            import fcntl
            global lock_fd
            lock_fd = open(LOCK_FILE, 'w')
            try:
                fcntl.lockf(lock_fd, fcntl.LOCK_EX | fcntl.LOCK_NB)
                return True
            except IOError:
                logger.error("å¦ä¸€ä¸ªå®ä¾‹æ­£åœ¨è¿è¡Œ")
                return False
    except Exception as e:
        logger.error(f"è·å–é”å¤±è´¥: {e}")
        return False

def release_lock():
    """é‡Šæ”¾é”"""
    try:
        if sys.platform == 'win32':
            if 'lock_file_handle' in globals():
                lock_file_handle.close()
                if os.path.exists(LOCK_FILE):
                    os.remove(LOCK_FILE)
        else:
            if 'lock_fd' in globals():
                lock_fd.close()
                if os.path.exists(LOCK_FILE):
                    os.remove(LOCK_FILE)
    except Exception as e:
        logger.error(f"é‡Šæ”¾é”å¤±è´¥: {e}")

atexit.register(release_lock)

# ===================== è·å–æœ¬æœºIPv4åœ°å€ =====================
def get_local_ip():
    """è·å–æœ¬æœºIPv4åœ°å€"""
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))
        ip = s.getsockname()[0]
        s.close()
        return ip
    except Exception:
        try:
            hostname = socket.gethostname()
            return socket.gethostbyname(hostname)
        except Exception:
            return "127.0.0.1"

LOCAL_IP = get_local_ip()

# ===================== Flaskåº”ç”¨å’Œæ•°æ®å­˜å‚¨ =====================
# æ³¨æ„ï¼šå‰ç«¯é™æ€æ–‡ä»¶å·²å†…ç½®åˆ°Flaskä¸­ï¼Œç»Ÿä¸€ç«¯å£æœåŠ¡
STATIC_FOLDER = os.path.join(os.getcwd(), "frontend", ".output", "public")
# ç¦ç”¨Flaskè‡ªåŠ¨é™æ€æ–‡ä»¶å¤„ç†ï¼Œæ”¹ç”¨catch_allè·¯ç”±æ‰‹åŠ¨å¤„ç†
app = Flask(__name__, static_folder=None)

# åº”ç”¨ProxyFixä¸­é—´ä»¶
app.wsgi_app = ProxyFix(app.wsgi_app, x_for=1, x_proto=1, x_host=1, x_prefix=1)

# CORSé…ç½® - æ›´å®Œå–„çš„é…ç½®
CORS(app, resources={
    r"/api/*": {
        "origins": ALLOWED_ORIGINS.split(',') if ALLOWED_ORIGINS != "*" else "*",
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization", "X-Requested-With"],
        "supports_credentials": True,
        "max_age": 3600
    },
    r"/image/*": {
        "origins": "*",
        "methods": ["GET", "HEAD", "OPTIONS"],
        "allow_headers": ["Content-Type", "Range", "Cache-Control"],
        "expose_headers": ["Content-Length", "Content-Range", "Accept-Ranges", "ETag", "Cache-Control"],
        "max_age": 86400
    },
    r"/static/*": {
        "origins": "*",
        "methods": ["GET", "HEAD", "OPTIONS"],
        "allow_headers": ["Content-Type"],
        "max_age": 86400
    }
})

app.secret_key = SECRET_KEY

# é…ç½®ç®¡ç†å‘˜ä¼šè¯
admin_module.configure_admin_session(app)

# å…¨å±€å˜é‡
start_time = time.time()
telegram_app = None
bot_info = None  # å­˜å‚¨æœºå™¨äººä¿¡æ¯

# CDNç¼“å­˜ç›‘æ§é˜Ÿåˆ—
cdn_monitor_queue = queue.Queue(maxsize=CDN_MONITOR_QUEUE_SIZE)
cdn_monitor_thread = None
cdn_monitor_running = False

# ===================== é™æ€æ–‡ä»¶ç‰ˆæœ¬ç®¡ç† =====================
def get_static_file_version(filename):
    """è·å–é™æ€æ–‡ä»¶ç‰ˆæœ¬å·"""
    if FORCE_REFRESH:
        return str(int(time.time()))
    return STATIC_VERSION

app.jinja_env.globals.update(get_static_file_version=get_static_file_version)

# ===================== Cloudflare CDN é›†æˆ =====================
class CloudflareCDN:
    """Cloudflare CDN ç®¡ç†ç±»"""
    
    def __init__(self):
        self.api_token = CLOUDFLARE_API_TOKEN
        self.zone_id = CLOUDFLARE_ZONE_ID
        self.cdn_domain = CLOUDFLARE_CDN_DOMAIN
        self.headers = {
            'Authorization': f'Bearer {self.api_token}',
            'Content-Type': 'application/json'
        }
        self.base_url = 'https://api.cloudflare.com/client/v4'
    
    def purge_cache(self, urls: List[str]) -> bool:
        """æ¸…é™¤æŒ‡å®šURLçš„ç¼“å­˜"""
        if not self.api_token or not self.zone_id:
            return False
        
        try:
            response = requests.post(
                f'{self.base_url}/zones/{self.zone_id}/purge_cache',
                headers=self.headers,
                json={'files': urls}
            )
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Cloudflareç¼“å­˜æ¸…é™¤å¤±è´¥: {e}")
            return False
    
    def check_cdn_status(self, encrypted_id: str) -> bool:
        """æ£€æŸ¥å›¾ç‰‡æ˜¯å¦è¢«CDNç¼“å­˜ - ä¿®å¤ç‰ˆ"""
        if not self.cdn_domain:
            return False
        
        try:
            cdn_url = f"https://{self.cdn_domain}/image/{encrypted_id}"
            
            # å‘é€HEADè¯·æ±‚æ£€æŸ¥ï¼Œæ·»åŠ ç‰¹æ®Šå¤´éƒ¨é¿å…è§¦å‘é‡å®šå‘
            headers = {
                'User-Agent': 'CDN-Status-Checker/1.0',
                'X-CDN-Check': 'true',
                'X-Skip-Redirect': 'true'
            }
            
            response = requests.head(
                cdn_url, 
                timeout=10, 
                allow_redirects=False,  # ä¸è·Ÿéšé‡å®šå‘
                headers=headers
            )
            
            # å¦‚æœè¿”å›302é‡å®šå‘ï¼Œè¯´æ˜è¿˜æœªç¼“å­˜
            if response.status_code == 302:
                logger.debug(f"å›¾ç‰‡ {encrypted_id} è¿”å›302é‡å®šå‘ï¼Œæœªè¢«CDNç¼“å­˜")
                return False
            
            # æ£€æŸ¥CF-Cache-Statuså¤´éƒ¨
            cache_status = response.headers.get('CF-Cache-Status', '')
            
            # HITã€STALEã€UPDATINGã€REVALIDATEDéƒ½è®¤ä¸ºæ˜¯å·²ç¼“å­˜
            cached = cache_status in ['HIT', 'STALE', 'UPDATING', 'REVALIDATED']
            
            # å¦‚æœçŠ¶æ€ç æ˜¯200ä¸”æœ‰ç¼“å­˜çŠ¶æ€ï¼Œä¹Ÿè®¤ä¸ºæ˜¯å·²ç¼“å­˜
            if response.status_code == 200 and cache_status:
                cached = True
            
            if cached:
                logger.info(f"å›¾ç‰‡ {encrypted_id} CDNç¼“å­˜çŠ¶æ€: {cache_status}")
            else:
                logger.debug(f"å›¾ç‰‡ {encrypted_id} CDNç¼“å­˜çŠ¶æ€: {cache_status or 'MISS'}")
            
            return cached
            
        except requests.exceptions.Timeout:
            logger.warning(f"æ£€æŸ¥CDNçŠ¶æ€è¶…æ—¶ {encrypted_id}")
            return False
        except Exception as e:
            logger.debug(f"æ£€æŸ¥CDNçŠ¶æ€å¤±è´¥ {encrypted_id}: {e}")
            return False
    
    async def warm_cache(self, url: str, encrypted_id: str = None):
        """é¢„çƒ­ç¼“å­˜ - ä¿®å¤ç‰ˆ"""
        if not ENABLE_CACHE_WARMING:
            return
        
        if not encrypted_id and '/image/' in url:
            encrypted_id = url.split('/image/')[-1].split('?')[0]
        
        await asyncio.sleep(CACHE_WARMING_DELAY)
        
        try:
            edge_locations = ['sfo', 'lax', 'ord', 'dfw', 'iad', 'lhr', 'fra', 'nrt', 'sin']
            
            async with aiohttp.ClientSession() as session:
                tasks = []
                for location in edge_locations:
                    headers = {
                        'CF-IPCountry': location.upper(),
                        'User-Agent': 'Cloudflare-Cache-Warmer/1.0',
                        'X-Cache-Warming': 'true'
                    }
                    task = session.get(url, headers=headers, timeout=10, allow_redirects=True)
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                success_count = sum(1 for r in results if not isinstance(r, Exception) and r.status in [200, 304])
                logger.info(f"ç¼“å­˜é¢„çƒ­å®Œæˆ: {url}, æˆåŠŸ: {success_count}/{len(edge_locations)}")
                
                if success_count > 0 and encrypted_id:
                    update_cdn_cache_status(encrypted_id, True)
                
        except Exception as e:
            logger.error(f"ç¼“å­˜é¢„çƒ­å¤±è´¥: {e}")

cloudflare_cdn = CloudflareCDN()

# ===================== CDNç¼“å­˜ç›‘æ§çº¿ç¨‹ =====================
def cdn_cache_monitor_worker():
    """CDNç¼“å­˜ç›‘æ§å·¥ä½œçº¿ç¨‹"""
    global cdn_monitor_running
    
    logger.info("CDNç¼“å­˜ç›‘æ§çº¿ç¨‹å¯åŠ¨")
    
    while cdn_monitor_running:
        try:
            # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡ï¼ˆé˜»å¡æœ€å¤š5ç§’ï¼‰
            try:
                task = cdn_monitor_queue.get(timeout=5)
            except queue.Empty:
                continue
            
            if task is None:  # åœæ­¢ä¿¡å·
                break
            
            encrypted_id = task['encrypted_id']
            retries = task.get('retries', 0)
            upload_time = task.get('upload_time', time.time())
            
            # æ£€æŸ¥æ˜¯å¦å·²ç»ç¼“å­˜
            file_info = get_file_info(encrypted_id)
            if file_info and file_info.get('cdn_cached'):
                logger.debug(f"å›¾ç‰‡ {encrypted_id} å·²æ ‡è®°ä¸ºç¼“å­˜ï¼Œè·³è¿‡æ£€æŸ¥")
                continue
            
            # æ£€æŸ¥CDNç¼“å­˜çŠ¶æ€
            is_cached = cloudflare_cdn.check_cdn_status(encrypted_id)
            
            if is_cached:
                # æ›´æ–°æ•°æ®åº“
                update_cdn_cache_status(encrypted_id, True)
                logger.info(f"âœ… å›¾ç‰‡ {encrypted_id} å·²è¢«CDNç¼“å­˜ï¼ˆç¬¬{retries + 1}æ¬¡æ£€æŸ¥ï¼‰")
            else:
                # æœªç¼“å­˜ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
                if retries < CDN_MONITOR_MAX_RETRIES:
                    # é‡æ–°åŠ å…¥é˜Ÿåˆ—
                    time.sleep(CDN_MONITOR_INTERVAL)
                    task['retries'] = retries + 1
                    
                    try:
                        cdn_monitor_queue.put(task, block=False)
                        logger.debug(f"å›¾ç‰‡ {encrypted_id} ç¬¬{retries + 1}æ¬¡æ£€æŸ¥æœªç¼“å­˜ï¼Œç»§ç»­ç›‘æµ‹...")
                    except queue.Full:
                        logger.warning(f"CDNç›‘æ§é˜Ÿåˆ—å·²æ»¡ï¼Œæ”¾å¼ƒç›‘æ§ {encrypted_id}")
                else:
                    # è¶…è¿‡æœ€å¤§é‡è¯•æ¬¡æ•°
                    logger.warning(f"å›¾ç‰‡ {encrypted_id} åœ¨{CDN_MONITOR_MAX_RETRIES * CDN_MONITOR_INTERVAL}ç§’å†…æœªè¢«ç¼“å­˜")
                    
                    # å°è¯•ä¸»åŠ¨é¢„çƒ­
                    if ENABLE_CACHE_WARMING and CLOUDFLARE_CDN_DOMAIN:
                        cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}"
                        logger.info(f"å°è¯•ä¸»åŠ¨é¢„çƒ­CDN: {encrypted_id}")
                        
                        try:
                            # åŒæ­¥é¢„çƒ­è¯·æ±‚
                            response = requests.get(cdn_url, timeout=30)
                            if response.status_code == 200:
                                logger.info(f"CDNé¢„çƒ­æˆåŠŸ: {encrypted_id}")
                                # ç¨åå†æ£€æŸ¥ä¸€æ¬¡
                                time.sleep(5)
                                if cloudflare_cdn.check_cdn_status(encrypted_id):
                                    update_cdn_cache_status(encrypted_id, True)
                        except Exception as e:
                            logger.error(f"CDNé¢„çƒ­å¤±è´¥: {e}")
            
        except Exception as e:
            logger.error(f"CDNç›‘æ§çº¿ç¨‹é”™è¯¯: {e}")
            time.sleep(1)
    
    logger.info("CDNç¼“å­˜ç›‘æ§çº¿ç¨‹å·²åœæ­¢")

def start_cdn_monitor():
    """å¯åŠ¨CDNç›‘æ§çº¿ç¨‹"""
    global cdn_monitor_thread, cdn_monitor_running
    
    if not CDN_ENABLED or not CLOUDFLARE_CDN_DOMAIN or not CDN_MONITOR_ENABLED:
        logger.info("CDNç›‘æ§æœªå¯ç”¨")
        return
    
    if cdn_monitor_thread and cdn_monitor_thread.is_alive():
        logger.warning("CDNç›‘æ§çº¿ç¨‹å·²åœ¨è¿è¡Œ")
        return
    
    cdn_monitor_running = True
    cdn_monitor_thread = threading.Thread(target=cdn_cache_monitor_worker, daemon=True)
    cdn_monitor_thread.start()
    logger.info("CDNç›‘æ§å·²å¯åŠ¨")

def stop_cdn_monitor():
    """åœæ­¢CDNç›‘æ§çº¿ç¨‹"""
    global cdn_monitor_running
    
    if not cdn_monitor_thread:
        return
    
    logger.info("æ­£åœ¨åœæ­¢CDNç›‘æ§...")
    cdn_monitor_running = False
    
    # å‘é€åœæ­¢ä¿¡å·
    try:
        cdn_monitor_queue.put(None, block=False)
    except:
        pass
    
    # ç­‰å¾…çº¿ç¨‹ç»“æŸ
    if cdn_monitor_thread.is_alive():
        cdn_monitor_thread.join(timeout=10)
    
    logger.info("CDNç›‘æ§å·²åœæ­¢")

def add_to_cdn_monitor(encrypted_id: str, upload_time: int = None):
    """æ·»åŠ å›¾ç‰‡åˆ°CDNç›‘æ§é˜Ÿåˆ—"""
    if not CDN_MONITOR_ENABLED or not CLOUDFLARE_CDN_DOMAIN:
        return
    
    task = {
        'encrypted_id': encrypted_id,
        'upload_time': upload_time or int(time.time()),
        'retries': 0
    }
    
    try:
        cdn_monitor_queue.put(task, block=False)
        logger.info(f"å›¾ç‰‡ {encrypted_id} å·²åŠ å…¥CDNç›‘æ§é˜Ÿåˆ—")
    except queue.Full:
        logger.warning(f"CDNç›‘æ§é˜Ÿåˆ—å·²æ»¡ï¼Œæ— æ³•æ·»åŠ  {encrypted_id}")

# ===================== æ•°æ®åº“åˆå§‹åŒ– =====================
def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“ - ç®€åŒ–ç‰ˆï¼Œæ— ç»Ÿè®¡è¡¨"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        # åˆ›å»ºä¸»è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS file_storage (
                encrypted_id TEXT PRIMARY KEY,
                file_id TEXT NOT NULL,
                file_path TEXT NOT NULL,
                upload_time INTEGER NOT NULL,
                user_id INTEGER,
                username TEXT,
                file_size INTEGER,
                source TEXT,
                original_filename TEXT,
                mime_type TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                etag TEXT,
                file_hash TEXT,
                cdn_url TEXT,
                cdn_cached BOOLEAN DEFAULT 0,
                cdn_cache_time TIMESTAMP,
                access_count INTEGER DEFAULT 0,
                last_accessed TIMESTAMP,
                last_file_path_update TIMESTAMP,
                is_group_upload BOOLEAN DEFAULT 0,
                group_message_id INTEGER,
                auth_token TEXT
            )
        ''')

        # åˆ›å»ºauth_tokensè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS auth_tokens (
                token TEXT PRIMARY KEY,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                expires_at TIMESTAMP,
                last_used TIMESTAMP,
                upload_count INTEGER DEFAULT 0,
                upload_limit INTEGER DEFAULT 100,
                is_active BOOLEAN DEFAULT 1,
                ip_address TEXT,
                user_agent TEXT,
                description TEXT
            )
        ''')

        # åˆ›å»ºå…¬å‘Šè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS announcements (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                enabled BOOLEAN DEFAULT 1,
                content TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # æ’å…¥é»˜è®¤å…¬å‘Šï¼ˆå¦‚æœè¡¨ä¸ºç©ºï¼‰
        cursor.execute('SELECT COUNT(*) FROM announcements')
        if cursor.fetchone()[0] == 0:
            cursor.execute('''
                INSERT INTO announcements (enabled, content) VALUES (?, ?)
            ''', (1, '''
                <div class="space-y-4">
                    <h3 class="text-xl font-bold text-gray-900 dark:text-white">æ¬¢è¿ä½¿ç”¨ Telegram äº‘å›¾åºŠ</h3>
                    <div class="space-y-2 text-gray-700 dark:text-gray-300">
                        <p>ğŸ‰ <strong>æ— é™åˆ¶ä½¿ç”¨ï¼š</strong>æ— ä¸Šä¼ æ•°é‡é™åˆ¶ï¼Œæ— æ—¶é—´é™åˆ¶</p>
                        <p>ğŸš€ <strong>CDNåŠ é€Ÿï¼š</strong>å…¨çƒCDNåŠ é€Ÿï¼Œè®¿é—®æ›´å¿«</p>
                        <p>ğŸ”’ <strong>å®‰å…¨å¯é ï¼š</strong>åŸºäºTelegramäº‘å­˜å‚¨ï¼Œæ°¸ä¹…ä¿å­˜</p>
                        <p>ğŸ’ <strong>Tokenæ¨¡å¼ï¼š</strong>ç”Ÿæˆä¸“å±Tokenï¼Œç®¡ç†æ‚¨çš„å›¾ç‰‡</p>
                    </div>
                </div>
            '''))

        # åˆ›å»ºç®¡ç†å‘˜é…ç½®è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS admin_config (
                key TEXT PRIMARY KEY,
                value TEXT NOT NULL,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

        # æ’å…¥é»˜è®¤ç®¡ç†å‘˜é…ç½®ï¼ˆå¦‚æœè¡¨ä¸ºç©ºï¼‰
        cursor.execute("SELECT COUNT(*) FROM admin_config")
        if cursor.fetchone()[0] == 0:
            import hashlib
            default_username = os.getenv("ADMIN_USERNAME", "admin")
            default_password = os.getenv("ADMIN_PASSWORD", "admin123")
            password_hash = hashlib.sha256(default_password.encode()).hexdigest()

            cursor.execute("INSERT INTO admin_config (key, value) VALUES (?, ?)",
                          ('username', default_username))
            cursor.execute("INSERT INTO admin_config (key, value) VALUES (?, ?)",
                          ('password_hash', password_hash))
            logger.info(f"å·²åˆå§‹åŒ–ç®¡ç†å‘˜é…ç½®: ç”¨æˆ·å={default_username}")
        
        # æ£€æŸ¥å¹¶æ·»åŠ æ–°åˆ—ï¼ˆç”¨äºå‡çº§ç°æœ‰æ•°æ®åº“ï¼‰
        cursor.execute("PRAGMA table_info(file_storage)")
        columns = [column[1] for column in cursor.fetchall()]
        
        # æ·»åŠ ç¼ºå¤±çš„åˆ—
        if 'is_group_upload' not in columns:
            logger.info("æ·»åŠ  is_group_upload åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN is_group_upload BOOLEAN DEFAULT 0')
        
        if 'group_message_id' not in columns:
            logger.info("æ·»åŠ  group_message_id åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN group_message_id INTEGER')
        
        if 'last_file_path_update' not in columns:
            logger.info("æ·»åŠ  last_file_path_update åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN last_file_path_update TIMESTAMP')
        
        if 'etag' not in columns:
            logger.info("æ·»åŠ  etag åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN etag TEXT')
        
        if 'file_hash' not in columns:
            logger.info("æ·»åŠ  file_hash åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN file_hash TEXT')
        
        if 'cdn_url' not in columns:
            logger.info("æ·»åŠ  cdn_url åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN cdn_url TEXT')
        
        if 'cdn_cached' not in columns:
            logger.info("æ·»åŠ  cdn_cached åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN cdn_cached BOOLEAN DEFAULT 0')
        
        if 'cdn_cache_time' not in columns:
            logger.info("æ·»åŠ  cdn_cache_time åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN cdn_cache_time TIMESTAMP')
        
        if 'access_count' not in columns:
            logger.info("æ·»åŠ  access_count åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN access_count INTEGER DEFAULT 0')
        
        if 'last_accessed' not in columns:
            logger.info("æ·»åŠ  last_accessed åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN last_accessed TIMESTAMP')

        if 'auth_token' not in columns:
            logger.info("æ·»åŠ  auth_token åˆ—")
            cursor.execute('ALTER TABLE file_storage ADD COLUMN auth_token TEXT')

        # åˆ›å»ºç´¢å¼•
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_file_storage_created ON file_storage(created_at)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_original_filename ON file_storage(original_filename)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_file_size ON file_storage(file_size)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_cdn_cached ON file_storage(cdn_cached)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_group_upload ON file_storage(is_group_upload)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_auth_token ON file_storage(auth_token)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_auth_tokens_expires ON auth_tokens(expires_at)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_auth_tokens_active ON auth_tokens(is_active)')
        
        conn.commit()
        conn.close()
        logger.info(f"æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ: {DATABASE_PATH}")
        
        # æ¢å¤æœªå®Œæˆçš„CDNç›‘æ§ä»»åŠ¡
        if CDN_MONITOR_ENABLED:
            restore_cdn_monitor_tasks()
        
    except Exception as e:
        logger.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        raise

def restore_cdn_monitor_tasks():
    """æ¢å¤æœªå®Œæˆçš„CDNç›‘æ§ä»»åŠ¡"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()
        
        # æŸ¥æ‰¾æœªç¼“å­˜çš„è¿‘æœŸå›¾ç‰‡ï¼ˆ24å°æ—¶å†…ï¼‰
        cursor.execute('''
            SELECT encrypted_id, upload_time FROM file_storage 
            WHERE cdn_cached = 0 
            AND upload_time > ? 
            AND cdn_url IS NOT NULL
            ORDER BY upload_time DESC
            LIMIT 100
        ''', (int(time.time()) - 86400,))
        
        rows = cursor.fetchall()
        conn.close()
        
        if rows:
            logger.info(f"æ¢å¤ {len(rows)} ä¸ªCDNç›‘æ§ä»»åŠ¡")
            for encrypted_id, upload_time in rows:
                add_to_cdn_monitor(encrypted_id, upload_time)
        
    except Exception as e:
        logger.error(f"æ¢å¤CDNç›‘æ§ä»»åŠ¡å¤±è´¥: {e}")

# ===================== è·å–åŸŸåå‡½æ•° =====================
def get_domain(request):
    """æ ¹æ®è¯·æ±‚åŠ¨æ€è·å–åŸŸå"""
    if request:
        if CDN_ENABLED and CLOUDFLARE_CDN_DOMAIN:
            if request.path.startswith('/api/'):
                pass
            else:
                return f"https://{CLOUDFLARE_CDN_DOMAIN}"
        
        cf_visitor = request.headers.get('CF-Visitor')
        if cf_visitor:
            try:
                visitor_data = json.loads(cf_visitor)
                scheme = visitor_data.get('scheme', 'https')
            except:
                scheme = 'https'
        else:
            scheme = request.headers.get('X-Forwarded-Proto', 'http')
        
        host = (request.headers.get('X-Forwarded-Host') or 
                request.headers.get('Host') or 
                request.host)
        
        base_url = f"{scheme}://{host}"
        
        forwarded_prefix = request.headers.get('X-Forwarded-Prefix', '')
        if forwarded_prefix:
            base_url += forwarded_prefix.rstrip('/')
            
        return base_url
    
    return f"http://{LOCAL_IP}:{PORT}"

# ===================== åŸºç¡€å‡½æ•° =====================
def get_fresh_file_path(file_id: str) -> Optional[str]:
    """é€šè¿‡Telegram APIè·å–æœ€æ–°çš„æ–‡ä»¶è·¯å¾„"""
    if not BOT_TOKEN or not file_id:
        return None
    
    try:
        # è°ƒç”¨getFile APIè·å–æœ€æ–°çš„file_path
        response = requests.get(
            f"https://api.telegram.org/bot{BOT_TOKEN}/getFile",
            params={'file_id': file_id},
            timeout=10
        )
        
        if response.ok:
            result = response.json()
            if result.get('ok') and result.get('result'):
                file_path = result['result'].get('file_path')
                logger.debug(f"è·å–æœ€æ–°file_pathæˆåŠŸ: {file_id} -> {file_path}")
                return file_path
        
        logger.error(f"è·å–æ–‡ä»¶è·¯å¾„å¤±è´¥: {response.text}")
        return None
        
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶è·¯å¾„å¼‚å¸¸: {e}")
        return None

def update_file_path_in_db(encrypted_id: str, new_file_path: str):
    """æ›´æ–°æ•°æ®åº“ä¸­çš„æ–‡ä»¶è·¯å¾„"""
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            UPDATE file_storage 
            SET file_path = ?, last_file_path_update = CURRENT_TIMESTAMP
            WHERE encrypted_id = ?
        ''', (new_file_path, encrypted_id))
        conn.commit()
        logger.debug(f"æ›´æ–°file_path: {encrypted_id} -> {new_file_path}")
    except Exception as e:
        logger.error(f"æ›´æ–°file_pathå¤±è´¥: {e}")
    finally:
        conn.close()

def update_cdn_cache_status(encrypted_id: str, cached: bool):
    """æ›´æ–°CDNç¼“å­˜çŠ¶æ€"""
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            UPDATE file_storage 
            SET cdn_cached = ?, cdn_cache_time = CURRENT_TIMESTAMP
            WHERE encrypted_id = ?
        ''', (1 if cached else 0, encrypted_id))
        conn.commit()
        logger.info(f"æ›´æ–°CDNç¼“å­˜çŠ¶æ€: {encrypted_id} -> {'å·²ç¼“å­˜' if cached else 'æœªç¼“å­˜'}")
    except Exception as e:
        logger.error(f"æ›´æ–°CDNç¼“å­˜çŠ¶æ€å¤±è´¥: {e}")
    finally:
        conn.close()

def update_access_count(encrypted_id: str):
    """æ›´æ–°è®¿é—®è®¡æ•°"""
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            UPDATE file_storage 
            SET access_count = access_count + 1,
                last_accessed = CURRENT_TIMESTAMP
            WHERE encrypted_id = ?
        ''', (encrypted_id,))
        conn.commit()
    except Exception as e:
        logger.error(f"æ›´æ–°è®¿é—®è®¡æ•°å¤±è´¥: {e}")
    finally:
        conn.close()

def get_file_info(encrypted_id: str) -> Optional[Dict[str, Any]]:
    """è·å–æ–‡ä»¶ä¿¡æ¯"""
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    try:
        cursor.execute('''
            SELECT * FROM file_storage 
            WHERE encrypted_id = ?
        ''', (encrypted_id,))
        
        row = cursor.fetchone()
        return dict(row) if row else None
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
        return None
    finally:
        conn.close()

def save_file_info(encrypted_id: str, file_info: Dict[str, Any]):
    """ä¿å­˜æ–‡ä»¶ä¿¡æ¯åˆ°æ•°æ®åº“"""
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    try:
        etag = f'W/"{encrypted_id}-{file_info.get("file_size", 0)}"'
        
        cdn_url = None
        if CDN_ENABLED and CLOUDFLARE_CDN_DOMAIN:
            cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}"
        
        # æ£€æŸ¥è¡¨ç»“æ„ï¼ŒåŠ¨æ€æ„å»ºINSERTè¯­å¥
        cursor.execute("PRAGMA table_info(file_storage)")
        columns = [column[1] for column in cursor.fetchall()]
        
        # åŸºç¡€å­—æ®µï¼ˆæ‰€æœ‰ç‰ˆæœ¬éƒ½æœ‰çš„ï¼‰
        insert_columns = ['encrypted_id', 'file_id', 'file_path', 'upload_time',
                         'username', 'file_size', 'source',
                         'original_filename', 'mime_type']
        insert_values = [
            encrypted_id,
            file_info['file_id'],
            file_info.get('file_path', ''),  # æ·»åŠ file_pathå­—æ®µ
            file_info['upload_time'],
            file_info.get('username', 'unknown'),
            file_info.get('file_size', 0),
            file_info.get('source', 'unknown'),
            file_info.get('original_filename', ''),
            file_info.get('mime_type', 'image/jpeg')
        ]
        
        # å¯é€‰å­—æ®µï¼ˆæ–°ç‰ˆæœ¬æ·»åŠ çš„ï¼‰
        optional_fields = {
            'etag': etag,
            'file_hash': file_info.get('file_hash', ''),
            'cdn_url': cdn_url,
            'cdn_cached': 0,
            'created_at': datetime.now().isoformat(),  # æ·»åŠ åˆ›å»ºæ—¶é—´ç”¨äºä»Šæ—¥ä¸Šä¼ ç»Ÿè®¡
            'is_group_upload': file_info.get('is_group_upload', 0),
            'group_message_id': file_info.get('group_message_id', None),
            'auth_token': file_info.get('auth_token', None)  # æ·»åŠ Tokenå­—æ®µ
        }
        
        # åªæ·»åŠ å­˜åœ¨çš„åˆ—
        for col, val in optional_fields.items():
            if col in columns:
                insert_columns.append(col)
                insert_values.append(val)
        
        # æ„å»ºSQLè¯­å¥
        placeholders = ','.join(['?' for _ in insert_columns])
        columns_str = ','.join(insert_columns)
        
        cursor.execute(f'''
            INSERT INTO file_storage ({columns_str}) 
            VALUES ({placeholders})
        ''', insert_values)
        
        conn.commit()
        logger.info(f"æ–‡ä»¶ä¿¡æ¯å·²ä¿å­˜: {encrypted_id}")
        
        # æ·»åŠ åˆ°CDNç›‘æ§é˜Ÿåˆ—
        if CDN_ENABLED and CLOUDFLARE_CDN_DOMAIN and CDN_MONITOR_ENABLED:
            add_to_cdn_monitor(encrypted_id, file_info['upload_time'])
        
        # è§¦å‘å¼‚æ­¥ç¼“å­˜é¢„çƒ­
        if CDN_ENABLED and ENABLE_CACHE_WARMING and cdn_url:
            asyncio.create_task(cloudflare_cdn.warm_cache(cdn_url, encrypted_id))
        
    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
        conn.rollback()
    finally:
        conn.close()

def get_stats() -> Dict[str, Any]:
    """è·å–åŸºç¡€ç»Ÿè®¡ä¿¡æ¯"""
    conn = sqlite3.connect(DATABASE_PATH)
    cursor = conn.cursor()
    
    try:
        # è·å–æ€»æ–‡ä»¶æ•°å’Œå¤§å°
        cursor.execute('SELECT COUNT(*), SUM(file_size) FROM file_storage')
        total_files, total_size = cursor.fetchone()
        total_size = total_size or 0

        # è·å–ä»Šæ—¥ä¸Šä¼ æ•° - ä¿®å¤æ—¥æœŸæŸ¥è¯¢
        today_start = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
        today_end = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)

        # ä½¿ç”¨æ—¶é—´æˆ³èŒƒå›´æŸ¥è¯¢ï¼Œå…¼å®¹ä¸åŒçš„æ—¥æœŸæ ¼å¼
        today_start_ts = int(today_start.timestamp())
        today_end_ts = int(today_end.timestamp())

        cursor.execute('''
            SELECT COUNT(*) FROM file_storage
            WHERE upload_time >= ? AND upload_time <= ?
        ''', (today_start_ts, today_end_ts))
        today_uploads = cursor.fetchone()[0]
        
        # è·å–CDNç¼“å­˜çš„æ–‡ä»¶æ•°
        cursor.execute('SELECT COUNT(*) FROM file_storage WHERE cdn_cached = 1')
        cached_files = cursor.fetchone()[0]
        
        # è·å–å¾…ç¼“å­˜æ•°
        cursor.execute('SELECT COUNT(*) FROM file_storage WHERE cdn_cached = 0 AND cdn_url IS NOT NULL')
        pending_cache = cursor.fetchone()[0]
        
        # è·å–ç¾¤ç»„ä¸Šä¼ æ•°ï¼ˆæ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨ï¼‰
        group_uploads = 0
        cursor.execute("PRAGMA table_info(file_storage)")
        columns = [column[1] for column in cursor.fetchall()]
        
        if 'is_group_upload' in columns:
            cursor.execute('SELECT COUNT(*) FROM file_storage WHERE is_group_upload = 1')
            group_uploads = cursor.fetchone()[0]
        
        return {
            'total_files': total_files,
            'total_size': total_size,
            'today_uploads': today_uploads,
            'group_uploads': group_uploads,
            'cdn_stats': {
                'cached_files': cached_files,
                'pending_cache': pending_cache,
                'monitor_queue_size': cdn_monitor_queue.qsize() if CDN_MONITOR_ENABLED else 0
            }
        }
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return {
            'total_files': 0,
            'total_size': 0,
            'today_uploads': 0,
            'group_uploads': 0,
            'cdn_stats': {
                'cached_files': 0,
                'pending_cache': 0,
                'monitor_queue_size': 0
            }
        }
    finally:
        conn.close()

def get_recent_uploads(limit: int = 10, page: int = 1) -> list:
    """è·å–æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶"""
    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    try:
        offset = (page - 1) * limit
        
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        cursor.execute("PRAGMA table_info(file_storage)")
        columns = [column[1] for column in cursor.fetchall()]
        
        # æ„å»ºSELECTè¯­å¥
        select_columns = ['encrypted_id', 'original_filename', 'file_size', 
                         'created_at', 'username', 'cdn_cached']
        
        if 'is_group_upload' in columns:
            select_columns.append('is_group_upload')
        
        columns_str = ', '.join(select_columns)
        
        cursor.execute(f'''
            SELECT {columns_str}
            FROM file_storage
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        ''', (limit, offset))
        
        results = []
        for row in cursor.fetchall():
            row_dict = dict(row)
            # å¦‚æœæ²¡æœ‰ is_group_upload åˆ—ï¼Œé»˜è®¤ä¸º 0
            if 'is_group_upload' not in row_dict:
                row_dict['is_group_upload'] = 0
            results.append(row_dict)
        
        return results
    except:
        return []
    finally:
        conn.close()

# ===================== CDNç¼“å­˜è£…é¥°å™¨ =====================
def add_cache_headers(response, cache_type='public', max_age=None):
    """æ·»åŠ CDNç¼“å­˜å¤´éƒ¨"""
    
    if 'Cache-Control' in response.headers and cache_type == 'public':
        response.headers['X-Content-Type-Options'] = 'nosniff'
        response.headers['X-Frame-Options'] = 'SAMEORIGIN'
        response.headers['X-XSS-Protection'] = '1; mode=block'
        return response
    
    if not CDN_ENABLED:
        if cache_type == 'static':
            response.headers['Cache-Control'] = 'public, max-age=3600'
        else:
            response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        return response
    
    if max_age is None:
        max_age = CDN_CACHE_TTL
    
    if cache_type == 'public':
        response.headers['Cache-Control'] = f'public, max-age={max_age}, s-maxage={CLOUDFLARE_EDGE_TTL}, stale-while-revalidate=86400, stale-if-error=604800'
        response.headers['Cloudflare-CDN-Cache-Control'] = f'max-age={CLOUDFLARE_EDGE_TTL}'
        response.headers['CDN-Cache-Control'] = f'max-age={CLOUDFLARE_EDGE_TTL}'
    elif cache_type == 'private':
        response.headers['Cache-Control'] = f'private, max-age={max_age}'
    elif cache_type == 'no-cache':
        response.headers['Cache-Control'] = 'no-cache, no-store, must-revalidate'
        response.headers['Pragma'] = 'no-cache'
        response.headers['Expires'] = '0'
    elif cache_type == 'static':
        response.headers['Cache-Control'] = f'public, max-age={CLOUDFLARE_BROWSER_TTL}, s-maxage={CLOUDFLARE_EDGE_TTL}'
    
    response.headers['X-Content-Type-Options'] = 'nosniff'
    response.headers['X-Frame-Options'] = 'SAMEORIGIN'
    response.headers['X-XSS-Protection'] = '1; mode=block'
    
    if cache_type in ['public', 'static']:
        response.headers['CF-Cache-Tag'] = 'imagebed'
    
    return response

# ===================== Flaskè·¯ç”± =====================
@app.route('/')
def index():
    """è¿”å›ä¸»é¡µ - æœåŠ¡å‰ç«¯é™æ€æ–‡ä»¶"""
    index_path = os.path.join(STATIC_FOLDER, 'index.html')
    if os.path.exists(index_path):
        return send_file(index_path)
    else:
        return jsonify({
            'error': 'å‰ç«¯æ–‡ä»¶æœªæ‰¾åˆ°',
            'message': 'è¯·å…ˆè¿è¡Œ cd frontend && npm run generate æ„å»ºå‰ç«¯',
            'api_base': get_domain(request)
        }), 404

@app.route('/image/<encrypted_id>', methods=['GET', 'HEAD', 'OPTIONS'])
def serve_image(encrypted_id):
    """ä»£ç†æä¾›Telegramå›¾ç‰‡æœåŠ¡ - ä¿®å¤æ–‡ä»¶è·¯å¾„è¿‡æœŸå’ŒåŠ è½½é—®é¢˜"""
    
    # å¤„ç†OPTIONSé¢„æ£€è¯·æ±‚
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, HEAD, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Range, Content-Type, Cache-Control'
        response.headers['Access-Control-Max-Age'] = '86400'
        return response
    
    # è·å–æ–‡ä»¶ä¿¡æ¯
    file_info = get_file_info(encrypted_id)
    
    if not file_info:
        logger.warning(f"å›¾ç‰‡æœªæ‰¾åˆ°: {encrypted_id}")
        response = Response(b'Image not found', status=404, mimetype='text/plain')
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache')
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯CDNå›æºè¯·æ±‚
    cf_headers = {k: v for k, v in request.headers.items() if k.startswith('CF-')}
    is_cdn_request = bool(cf_headers.get('CF-Connecting-IP'))
    
    # æ£€æŸ¥æ˜¯å¦æ¥è‡ªCDNåŸŸåï¼ˆé¿å…é‡å®šå‘å¾ªç¯ï¼‰
    host = request.headers.get('Host', '')
    is_from_cdn_domain = CLOUDFLARE_CDN_DOMAIN and host == CLOUDFLARE_CDN_DOMAIN
    
    # æ£€æŸ¥Refereræ˜¯å¦æ¥è‡ªCDNï¼ˆé¢å¤–çš„å¾ªç¯æ£€æµ‹ï¼‰
    referer = request.headers.get('Referer', '')
    is_referer_from_cdn = CLOUDFLARE_CDN_DOMAIN and CLOUDFLARE_CDN_DOMAIN in referer
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é‡å®šå‘å¾ªç¯æ ‡è®°
    redirect_count = request.headers.get('X-Redirect-Count', '0')
    try:
        redirect_count = int(redirect_count)
    except:
        redirect_count = 0
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æ–°ä¸Šä¼ çš„ï¼ˆç”¨äºé¿å…ç«‹å³é‡å®šå‘ï¼‰
    is_new_file = False
    if file_info.get('upload_time'):
        time_since_upload = time.time() - file_info['upload_time']
        is_new_file = time_since_upload < CDN_REDIRECT_DELAY
    
    # å¦‚æœä¸æ˜¯CDNå›æºè¯·æ±‚ï¼Œä¸æ˜¯æ¥è‡ªCDNåŸŸåï¼Œæ–‡ä»¶ä¸æ˜¯æ–°ä¸Šä¼ çš„ï¼Œä¸”æ²¡æœ‰é‡å®šå‘å¾ªç¯
    if (CDN_REDIRECT_ENABLED and  # æ£€æŸ¥æ˜¯å¦å¯ç”¨é‡å®šå‘
        not is_cdn_request and 
        not is_from_cdn_domain and 
        not is_referer_from_cdn and
        not is_new_file and  # æ–°æ–‡ä»¶ä¸ç«‹å³é‡å®šå‘
        redirect_count < CDN_REDIRECT_MAX_COUNT and  # ä½¿ç”¨é…ç½®çš„æœ€å¤§é‡å®šå‘æ¬¡æ•°
        CDN_ENABLED and 
        CLOUDFLARE_CDN_DOMAIN):
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²è¢«CDNç¼“å­˜
        if file_info.get('cdn_cached'):
            # æ„å»ºCDN URL
            cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}"
            
            # æ£€æŸ¥è¯·æ±‚URLæ˜¯å¦å·²ç»æ˜¯CDN URLï¼ˆé¿å…å¾ªç¯ï¼‰
            request_url = request.url
            if cdn_url not in request_url:
                logger.info(f"å›¾ç‰‡å·²ç¼“å­˜ï¼Œé‡å®šå‘åˆ°CDN: {encrypted_id} -> {cdn_url}")
                
                # æ›´æ–°è®¿é—®è®¡æ•°
                update_access_count(encrypted_id)
                
                # è¿”å›302é‡å®šå‘ï¼Œæ·»åŠ é‡å®šå‘è®¡æ•°å¤´éƒ¨
                response = redirect(cdn_url, code=302)
                response.headers['Cache-Control'] = f'public, max-age={CDN_REDIRECT_CACHE_TIME}'
                response.headers['X-CDN-Redirect'] = 'true'
                response.headers['X-Redirect-Count'] = str(redirect_count + 1)
                return response
            else:
                logger.warning(f"æ£€æµ‹åˆ°å¯èƒ½çš„é‡å®šå‘å¾ªç¯ï¼Œç›´æ¥æä¾›å›¾ç‰‡: {encrypted_id}")
        else:
            # å¦‚æœè¿˜æœªç¼“å­˜ï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¼“å­˜çŠ¶æ€
            if cloudflare_cdn.check_cdn_status(encrypted_id):
                update_cdn_cache_status(encrypted_id, True)
                logger.info(f"æ›´æ–°CDNç¼“å­˜çŠ¶æ€å¹¶ç›´æ¥æä¾›å›¾ç‰‡: {encrypted_id}")
    
    # ä»¥ä¸‹æ˜¯CDNå›æºè¯·æ±‚æˆ–ç›´æ¥æä¾›å›¾ç‰‡çš„å¤„ç†
    cache_status = cf_headers.get('CF-Cache-Status', '')
    
    # æ›´æ–°è®¿é—®è®¡æ•°
    update_access_count(encrypted_id)
    
    # å¦‚æœæ˜¯CDNè¯·æ±‚ä¸”çŠ¶æ€ä¸ºHITï¼Œæ›´æ–°ç¼“å­˜çŠ¶æ€
    if is_cdn_request and cache_status in ['HIT', 'STALE', 'UPDATING'] and not file_info.get('cdn_cached'):
        update_cdn_cache_status(encrypted_id, True)
    
    # ç”ŸæˆETag
    etag = file_info.get('etag') or f'W/"{encrypted_id}-{file_info.get("file_size", 0)}"'
    
    # æ£€æŸ¥æ¡ä»¶è¯·æ±‚
    if_none_match = request.headers.get('If-None-Match')
    if if_none_match and if_none_match == etag:
        # 304å“åº”
        response = Response(status=304)
        response.headers['ETag'] = etag
        response.headers['Cache-Control'] = 'public, max-age=31536000, s-maxage=2592000, immutable'
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
    
    # éœ€è¦ä»Telegramè·å–å›¾ç‰‡
    try:
        # è·å–æœ€æ–°çš„file_path
        fresh_file_path = get_fresh_file_path(file_info['file_id'])
        if not fresh_file_path:
            logger.error(f"æ— æ³•è·å–æœ€æ–°çš„file_path: {file_info['file_id']}")
            response = Response(b'Image not found', status=404, mimetype='text/plain')
            response.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(response, 'no-cache')
        
        # å¦‚æœfile_pathæœ‰å˜åŒ–ï¼Œæ›´æ–°æ•°æ®åº“
        if fresh_file_path != file_info['file_path']:
            update_file_path_in_db(encrypted_id, fresh_file_path)
        
        # æ„å»ºæ–‡ä»¶URL
        if fresh_file_path.startswith('https://'):
            file_url = fresh_file_path
        else:
            file_url = f"https://api.telegram.org/file/bot{BOT_TOKEN}/{fresh_file_path}"
        
        access_type = 'cdn_pull' if is_cdn_request else 'direct_access'
        logger.info(f"ä»Telegramè·å–å›¾ç‰‡: {encrypted_id} (è®¿é—®ç±»å‹: {access_type}, CDNçŠ¶æ€: {cache_status})")
        
        # æ”¯æŒèŒƒå›´è¯·æ±‚
        headers = {}
        range_header = request.headers.get('Range')
        if range_header:
            headers['Range'] = range_header
        
        # ä»Telegramè·å–å›¾ç‰‡
        response = requests.get(file_url, stream=True, timeout=30, headers=headers)
        
        if response.status_code in [200, 206]:
            content_type = file_info.get('mime_type') or response.headers.get('content-type', 'image/jpeg')
            
            file_ext = Path(fresh_file_path).suffix or '.jpg'
            filename = f"image_{encrypted_id[:12]}{file_ext}"
            
            def generate():
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        yield chunk
            
            resp_headers = {
                'Content-Disposition': f'inline; filename="{filename}"',
                'X-Content-Type-Options': 'nosniff',
                'Accept-Ranges': 'bytes',
                'ETag': etag,
                'X-Access-Type': access_type,
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Methods': 'GET, HEAD, OPTIONS',
                'Access-Control-Allow-Headers': 'Range, Cache-Control',
                'Access-Control-Expose-Headers': 'Content-Length, Content-Range, Accept-Ranges, ETag'
            }
            
            if 'content-length' in response.headers:
                resp_headers['Content-Length'] = response.headers['content-length']
            if 'content-range' in response.headers:
                resp_headers['Content-Range'] = response.headers['content-range']
            
            if file_info.get('created_at'):
                try:
                    created_at = datetime.fromisoformat(file_info['created_at'].replace('Z', '+00:00'))
                    resp_headers['Last-Modified'] = created_at.strftime('%a, %d %b %Y %H:%M:%S GMT')
                except:
                    pass
            
            resp = Response(
                generate(), 
                status=response.status_code,
                mimetype=content_type,
                headers=resp_headers
            )
            
            # è®¾ç½®ç¼“å­˜å¤´éƒ¨
            if CDN_ENABLED:
                # å¯¹äºæ–°æ–‡ä»¶ï¼Œä½¿ç”¨è¾ƒçŸ­çš„ç¼“å­˜æ—¶é—´
                if is_new_file:
                    resp.headers['Cache-Control'] = 'public, max-age=300, s-maxage=300'
                else:
                    resp.headers['Cache-Control'] = 'public, max-age=31536000, s-maxage=2592000, immutable'
                resp.headers.pop('Set-Cookie', None)
                resp.headers.pop('Cookie', None)
                resp.headers['Vary'] = 'Accept-Encoding'
                resp.headers['CF-Cache-Tag'] = f'image-{encrypted_id[:8]},imagebed,static'
            else:
                resp.headers['Cache-Control'] = 'public, max-age=3600'
            
            return resp
            
        else:
            logger.warning(f"Telegramæ–‡ä»¶è·å–å¤±è´¥: {file_url}, status: {response.status_code}")
            response = Response(b'Image not found', status=404, mimetype='text/plain')
            response.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(response, 'no-cache')
            
    except Exception as e:
        logger.error(f"ä»£ç†å›¾ç‰‡å¤±è´¥: {e}")
        response = Response(b'Error loading image', status=500, mimetype='text/plain')
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache')

@app.route('/api/upload', methods=['POST', 'OPTIONS'])
def upload_file():
    """å¤„ç†å‰ç«¯æ–‡ä»¶ä¸Šä¼ """
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return add_cache_headers(response, 'no-cache')
    
    global telegram_app
    
    if not telegram_app:
        response = jsonify({'error': 'Telegram bot not initialized'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500
    
    if 'file' not in request.files:
        response = jsonify({'error': 'No file provided'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400
    
    file = request.files['file']
    if file.filename == '':
        response = jsonify({'error': 'No file selected'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400
    
    if not file.content_type.startswith('image/'):
        response = jsonify({'error': 'Only image files are allowed'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400
    
    file.seek(0, 2)
    file_size = file.tell()
    file.seek(0)
    
    if file_size > 20 * 1024 * 1024:
        response = jsonify({'error': 'File size exceeds 20MB limit'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400
    
    try:
        file_content = file.read()
        file.seek(0)
        
        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_hash = hashlib.md5(file_content).hexdigest()
        
        # åˆ¤æ–­æ–‡ä»¶å¤§å°ï¼Œé€‰æ‹©åˆé€‚çš„ä¸Šä¼ æ–¹æ³•
        if file_size <= 10 * 1024 * 1024:  # 10MBä»¥ä¸‹ä½¿ç”¨sendPhoto
            files = {
                'photo': (file.filename, file_content, file.content_type)
            }
            data = {
                'chat_id': STORAGE_CHAT_ID,
                'caption': f"Webä¸Šä¼  | æ–‡ä»¶å: {file.filename} | å¤§å°: {file_size} bytes | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}"
            }
            
            response = requests.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto",
                files=files,
                data=data,
                timeout=30
            )
        else:  # 10MBä»¥ä¸Šä½¿ç”¨sendDocument
            files = {
                'document': (file.filename, file_content, file.content_type)
            }
            data = {
                'chat_id': STORAGE_CHAT_ID,
                'caption': f"Webä¸Šä¼ (å¤§æ–‡ä»¶) | æ–‡ä»¶å: {file.filename} | å¤§å°: {file_size} bytes | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}"
            }
            
            response = requests.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendDocument",
                files=files,
                data=data,
                timeout=60
            )
        
        if not response.ok:
            logger.error(f"Telegram API error: {response.text}")
            resp = jsonify({'error': 'Failed to upload to Telegram'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500
        
        result = response.json()
        if not result.get('ok'):
            logger.error(f"Telegram API failed: {result}")
            resp = jsonify({'error': 'Telegram API failed'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500
        
        # è·å–æ–‡ä»¶ä¿¡æ¯
        if file_size <= 10 * 1024 * 1024:
            photos = result['result']['photo']
            if not photos:
                resp = jsonify({'error': 'No photo in response'})
                resp.headers['Access-Control-Allow-Origin'] = '*'
                return add_cache_headers(resp, 'no-cache'), 500
            
            photo = photos[-1]
            file_id = photo['file_id']
        else:
            document = result['result']['document']
            if not document:
                resp = jsonify({'error': 'No document in response'})
                resp.headers['Access-Control-Allow-Origin'] = '*'
                return add_cache_headers(resp, 'no-cache'), 500
            
            file_id = document['file_id']
        
        file_response = requests.get(
            f"https://api.telegram.org/bot{BOT_TOKEN}/getFile",
            params={'file_id': file_id},
            timeout=30
        )
        
        if not file_response.ok:
            logger.error(f"Failed to get file info: {file_response.text}")
            resp = jsonify({'error': 'Failed to get file info'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500
        
        file_result = file_response.json()
        if not file_result.get('ok'):
            logger.error(f"Get file API failed: {file_result}")
            resp = jsonify({'error': 'Get file API failed'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500
        
        file_path = file_result['result']['file_path']
        tg_file_size = file_result['result'].get('file_size', file_size)
        
        logger.info(f"Telegramä¸Šä¼ æˆåŠŸ: file_id={file_id}, file_path={file_path}, size={tg_file_size}")
        
        encrypted_id = encrypt_file_id(file_id, file_path)
        
        mime_type = get_mime_type(file.filename)
        
        file_data = {
            'file_id': file_id,
            'file_path': file_path,
            'upload_time': int(time.time()),
            'user_id': 0,
            'username': 'web_user',
            'file_size': tg_file_size,
            'source': 'web_upload',
            'original_filename': file.filename,
            'mime_type': mime_type,
            'file_hash': file_hash,
            'is_group_upload': 0
        }
        save_file_info(encrypted_id, file_data)
        
        # ç”ŸæˆURL
        base_url = get_domain(request)
        permanent_url = f"{base_url}/image/{encrypted_id}"
        
        logger.info(f"Webä¸Šä¼ å®Œæˆ: {file.filename} -> {encrypted_id}")
        
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        def format_size(size_bytes):
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            elif size_bytes < 1024 * 1024 * 1024:
                return f"{size_bytes / 1024 / 1024:.1f} MB"
            else:
                return f"{size_bytes / 1024 / 1024 / 1024:.1f} GB"

        resp = jsonify({
            'success': True,
            'data': {
                'url': permanent_url,
                'filename': file.filename,
                'size': format_size(tg_file_size),
                'upload_time': time.strftime('%Y-%m-%d %H:%M:%S')
            }
        })
        
        resp.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(resp, 'no-cache')
        
    except Exception as e:
        logger.error(f"Upload error: {e}")
        resp = jsonify({'error': str(e)})
        resp.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(resp, 'no-cache'), 500

@app.route('/api/stats')
def get_stats_api():
    """è·å–ç»Ÿè®¡ä¿¡æ¯API"""
    stats = get_stats()

    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
    def format_size(size_bytes):
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / 1024 / 1024:.1f} MB"
        else:
            return f"{size_bytes / 1024 / 1024 / 1024:.1f} GB"

    # æ ¼å¼åŒ–è¿è¡Œæ—¶é—´
    uptime_seconds = int(time.time() - start_time)
    days = uptime_seconds // 86400
    hours = (uptime_seconds % 86400) // 3600
    minutes = (uptime_seconds % 3600) // 60

    if days > 0:
        uptime_str = f"{days}å¤©"
    elif hours > 0:
        uptime_str = f"{hours}å°æ—¶"
    else:
        uptime_str = f"{minutes}åˆ†é’Ÿ"

    response = jsonify({
        'success': True,
        'data': {
            'totalFiles': str(stats['total_files']),
            'totalSize': format_size(stats['total_size']),
            'todayUploads': str(stats['today_uploads']),
            'uptime': uptime_str
        }
    })

    response.headers['Access-Control-Allow-Origin'] = '*'
    # ç»Ÿè®¡æ•°æ®éœ€è¦å®æ—¶æ›´æ–°,ç¦ç”¨ç¼“å­˜
    return add_cache_headers(response, 'no-cache')

@app.route('/api/recent')
def get_recent_api():
    """è·å–æœ€è¿‘ä¸Šä¼ çš„æ–‡ä»¶"""
    limit = request.args.get('limit', 12, type=int)
    page = request.args.get('page', 1, type=int)
    
    try:
        recent_files = get_recent_uploads(limit, page)
        
        for file in recent_files:
            if file['created_at']:
                try:
                    dt = datetime.fromisoformat(file['created_at'].replace('Z', '+00:00'))
                    file['created_at'] = dt.strftime('%Y-%m-%d %H:%M:%S')
                except:
                    pass
            
            base_url = get_domain(request)
            file['image_url'] = f"{base_url}/image/{file['encrypted_id']}"
            file['cdn_url'] = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{file['encrypted_id']}" if CLOUDFLARE_CDN_DOMAIN else None
            file['cdn_cached'] = file.get('cdn_cached', 0)
            file['is_group_upload'] = file.get('is_group_upload', 0)
        
        response = jsonify({
            'success': True,
            'files': recent_files,
            'page': page,
            'limit': limit,
            'has_more': len(recent_files) == limit
        })

        response.headers['Access-Control-Allow-Origin'] = '*'
        # æœ€è¿‘ä¸Šä¼ æ•°æ®éœ€è¦å®æ—¶æ›´æ–°,ç¦ç”¨ç¼“å­˜
        return add_cache_headers(response, 'no-cache')
    
    except Exception as e:
        logger.error(f"Failed to get recent files: {e}")
        response = jsonify({
            'success': False,
            'error': 'Failed to load gallery',
            'files': [],
            'page': page,
            'limit': limit,
            'has_more': False
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

@app.route('/api/images')
def get_images_api():
    """è·å–å›¾ç‰‡åˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µ/æœç´¢/æ’åºï¼‰"""
    limit = request.args.get('limit', 24, type=int)
    page = request.args.get('page', 1, type=int)
    search = request.args.get('search', '', type=str).strip()
    sort = request.args.get('sort', 'newest', type=str)

    offset = (page - 1) * limit

    conn = sqlite3.connect(DATABASE_PATH)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    try:
        where_clauses = []
        params = []
        if search:
            where_clauses.append("(original_filename LIKE ? OR username LIKE ?)")
            like = f"%{search}%"
            params.extend([like, like])
        where_sql = f" WHERE {' AND '.join(where_clauses)}" if where_clauses else ""

        # ç»Ÿè®¡æ€»æ•°
        cursor.execute(f"SELECT COUNT(*) FROM file_storage{where_sql}", params)
        total = cursor.fetchone()[0] or 0

        # æ’åº
        if sort == 'oldest':
            order_by = 'created_at ASC'
        elif sort == 'name':
            order_by = 'original_filename COLLATE NOCASE ASC'
        elif sort == 'size':
            order_by = 'file_size DESC'
        else:
            order_by = 'created_at DESC'

        # æŸ¥è¯¢æ•°æ®
        cursor.execute(
            f"""
            SELECT encrypted_id, original_filename, file_size, created_at
            FROM file_storage
            {where_sql}
            ORDER BY {order_by}
            LIMIT ? OFFSET ?
            """,
            params + [limit, offset]
        )

        rows = cursor.fetchall()
        images = []
        base_url = get_domain(request)

        def format_size(size_bytes: int) -> str:
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            else:
                return f"{size_bytes / 1024 / 1024:.1f} MB"

        for row in rows:
            encrypted_id = row['encrypted_id']
            filename = row['original_filename'] or f"image_{encrypted_id[:8]}.jpg"
            size_str = format_size(row['file_size'] or 0)

            created_raw = row['created_at'] or ''
            upload_time = created_raw
            try:
                upload_time = datetime.fromisoformat(created_raw.replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S')
            except Exception:
                pass

            images.append({
                'id': encrypted_id,
                'url': f"{base_url}/image/{encrypted_id}",
                'filename': filename,
                'size': size_str,
                'uploadTime': upload_time
            })

        total_pages = (total + limit - 1) // limit or 1

        response = jsonify({
            'success': True,
            'data': {
                'images': images,
                'totalPages': total_pages
            }
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'private', 120)

    except Exception as e:
        logger.error(f"è·å–å›¾ç‰‡åˆ—è¡¨å¤±è´¥: {e}")
        response = jsonify({
            'success': False,
            'error': 'Failed to load images',
            'data': {
                'images': [],
                'totalPages': 1
            }
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

    finally:
        conn.close()

@app.route('/api/info')
def get_info():
    """è·å–æœåŠ¡å™¨ä¿¡æ¯"""
    stats = get_stats()
    
    response = jsonify({
        'server_ip': LOCAL_IP,
        'domain': get_domain(request),
        'cdn_domain': f"https://{CLOUDFLARE_CDN_DOMAIN}" if CLOUDFLARE_CDN_DOMAIN else None,
        'port': PORT,
        'storage_type': 'telegram_cloud + sqlite',
        'database_path': DATABASE_PATH,
        'bot_configured': bool(BOT_TOKEN),
        'storage_chat_configured': STORAGE_CHAT_ID != 0,
        'uptime': int(time.time() - start_time),
        'total_files': stats['total_files'],
        'group_uploads': stats['group_uploads'],
        'cdn_enabled': CDN_ENABLED,
        'cloudflare_cdn': bool(CLOUDFLARE_CDN_DOMAIN),
        'cdn_cache_ttl': CDN_CACHE_TTL if CDN_ENABLED else 0,
        'cloudflare_cache_level': CLOUDFLARE_CACHE_LEVEL,
        'smart_routing': ENABLE_SMART_ROUTING,
        'cache_warming': ENABLE_CACHE_WARMING,
        'cdn_monitor_enabled': CDN_MONITOR_ENABLED,
        'cdn_monitor_queue': stats['cdn_stats']['monitor_queue_size'],
        'cdn_redirect_enabled': CDN_REDIRECT_ENABLED,
        'cdn_redirect_max_count': CDN_REDIRECT_MAX_COUNT,
        'cdn_redirect_delay': CDN_REDIRECT_DELAY,
        'group_upload_enabled': ENABLE_GROUP_UPLOAD,
        'group_upload_admin_only': GROUP_UPLOAD_ADMIN_ONLY,
        'group_upload_reply': GROUP_UPLOAD_REPLY,
        'max_file_size': 20 * 1024 * 1024,
        'static_version': STATIC_VERSION,
        'features': [
            'telegram_cloud_storage',
            'web_upload',
            'drag_and_drop',
            'encrypted_links',
            'permanent_urls',
            'inline_image_viewing',
            'database_persistence',
            'multiple_copy_formats',
            'proxy_support',
            'cdn_support',
            'cloudflare_cdn_integration',
            'smart_routing',
            'cache_warming',
            'cache_optimization',
            'etag_support',
            'range_request_support',
            'large_file_support_20mb',
            'admin_dashboard',
            'version_control',
            'backend_cdn_monitoring',
            'automatic_cache_detection',
            'smart_cdn_redirect',
            'redirect_loop_prevention',
            'automatic_file_path_refresh',
            'telegram_file_expiry_handling',
            'new_file_redirect_delay',
            'improved_cors_support',
            'group_upload_support',
            'group_admin_control',
            'auto_reply_with_cdn_link'
        ]
    })

    response.headers['Access-Control-Allow-Origin'] = '*'
    # æœåŠ¡å™¨ä¿¡æ¯å¯ä»¥çŸ­æ—¶é—´ç¼“å­˜,ä½†ä¸åº”è¿‡é•¿
    return add_cache_headers(response, 'private', 60)

@app.route('/api/health')
def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    response = jsonify({
        'status': 'healthy',
        'timestamp': int(time.time()),
        'base_url': get_domain(request),
        'cdn_enabled': CDN_ENABLED,
        'cloudflare_cdn': bool(CLOUDFLARE_CDN_DOMAIN),
        'cdn_monitor_active': cdn_monitor_thread and cdn_monitor_thread.is_alive() if CDN_MONITOR_ENABLED else False,
        'cdn_redirect_enabled': CDN_REDIRECT_ENABLED,
        'group_upload_enabled': ENABLE_GROUP_UPLOAD,
        'version': STATIC_VERSION
    })
    response.headers['Access-Control-Allow-Origin'] = '*'
    return add_cache_headers(response, 'no-cache')

@app.route('/api/admin/check')
def check_admin_status():
    """æ£€æŸ¥ç®¡ç†å‘˜ç™»å½•çŠ¶æ€"""
    from flask import session
    is_authenticated = session.get('admin_authenticated', False)
    username = session.get('admin_username', '')
    
    response = jsonify({
        'authenticated': is_authenticated,
        'username': username
    })
    response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
    response.headers['Access-Control-Allow-Credentials'] = 'true'
    return add_cache_headers(response, 'no-cache')

@app.route('/robots.txt')
def robots():
    """æä¾›robots.txt"""
    robots_content = f"""User-agent: *
Allow: /
Disallow: /api/
Disallow: /admin

# Cloudflare
User-agent: Cloudflare-*
Allow: /

Sitemap: {get_domain(request)}/sitemap.xml
"""
    response = Response(robots_content, mimetype='text/plain')
    return add_cache_headers(response, 'public', 86400)

@app.route('/manifest.json')
def manifest():
    """æä¾›PWA manifest"""
    manifest_data = {
        "name": "Telegram äº‘å›¾åºŠ",
        "short_name": "äº‘å›¾åºŠ",
        "description": "åŸºäºTelegramäº‘å­˜å‚¨çš„å…è´¹å›¾åºŠæœåŠ¡ï¼ŒCloudflare CDNå…¨çƒåŠ é€Ÿ",
        "start_url": "/",
        "display": "standalone",
        "background_color": "#ffffff",
        "theme_color": "#6366f1",
        "orientation": "portrait-primary"
    }
    response = jsonify(manifest_data)
    return add_cache_headers(response, 'public', 86400)

@app.route('/sw.js')
def service_worker():
    """æä¾›Service Workerè„šæœ¬"""
    # ä»templates/sw.jsè¯»å–å†…å®¹
    sw_path = os.path.join(app.root_path, 'templates', 'sw.js')
    if os.path.exists(sw_path):
        with open(sw_path, 'r', encoding='utf-8') as f:
            sw_content = f.read()
    else:
        # ä½¿ç”¨é»˜è®¤å†…å®¹
        sw_content = f"""
// Service Worker for offline support and cache management
const CACHE_VERSION = 'telegram-imagebed-v{STATIC_VERSION}';
const STATIC_CACHE = CACHE_VERSION + '-static';
const IMAGE_CACHE = CACHE_VERSION + '-images';
const API_CACHE = CACHE_VERSION + '-api';
const CDN_DOMAIN = '{CLOUDFLARE_CDN_DOMAIN or ""}';

const urlsToCache = [
    '/',
    '/static/js/main.js?v={STATIC_VERSION}',
    '/static/css/styles.css?v={STATIC_VERSION}',
    '/static/css/admin.css?v={STATIC_VERSION}'
];

// çœç•¥å…¶ä»–Service Workerä»£ç ...
"""
    
    # æ›¿æ¢å˜é‡
    sw_content = sw_content.replace('{STATIC_VERSION}', STATIC_VERSION)
    sw_content = sw_content.replace('{CLOUDFLARE_CDN_DOMAIN or ""}', CLOUDFLARE_CDN_DOMAIN or '')
    
    response = Response(sw_content, mimetype='application/javascript')
    return add_cache_headers(response, 'private', 3600)

# CDNç®¡ç†API
@app.route('/api/admin/cdn/purge', methods=['POST', 'OPTIONS'])
@admin_module.login_required
def purge_cdn_cache():
    """æ¸…é™¤CDNç¼“å­˜ï¼ˆç®¡ç†å‘˜ï¼‰"""
    data = request.get_json()
    urls = data.get('urls', [])
    
    if not urls:
        response = jsonify({'error': 'No URLs provided'})
        return add_cache_headers(response, 'no-cache'), 400
    
    cdn_urls = []
    for url in urls:
        if '/image/' in url:
            encrypted_id = url.split('/image/')[-1]
            if CLOUDFLARE_CDN_DOMAIN:
                cdn_urls.append(f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}")
    
    if cdn_urls and cloudflare_cdn.purge_cache(cdn_urls):
        response = jsonify({
            'success': True,
            'message': f'å·²æ¸…é™¤ {len(cdn_urls)} ä¸ªURLçš„ç¼“å­˜'
        })
    else:
        response = jsonify({
            'success': False,
            'error': 'ç¼“å­˜æ¸…é™¤å¤±è´¥'
        })
    
    return add_cache_headers(response, 'no-cache')

@app.route('/api/admin/clear_cache', methods=['POST', 'OPTIONS'])
@admin_module.login_required
def clear_cache():
    """æ¸…ç†CDNç¼“å­˜ï¼ˆä»…é™ç®¡ç†å‘˜ï¼‰"""
    global STATIC_VERSION
    old_version = STATIC_VERSION
    STATIC_VERSION = str(int(time.time()))

    cloudflare_success = False
    if CLOUDFLARE_CDN_DOMAIN and cloudflare_cdn.zone_id:
        try:
            response = requests.post(
                f'{cloudflare_cdn.base_url}/zones/{cloudflare_cdn.zone_id}/purge_cache',
                headers=cloudflare_cdn.headers,
                json={'purge_everything': True}
            )

            if response.status_code == 200:
                message = 'ç¼“å­˜å·²æ¸…ç†ï¼ŒCloudflareç¼“å­˜å·²æ¸…é™¤'
                cloudflare_success = True
            else:
                message = 'ç¼“å­˜å·²æ¸…ç†ï¼Œä½†Cloudflareç¼“å­˜æ¸…é™¤å¤±è´¥'
        except:
            message = 'ç¼“å­˜å·²æ¸…ç†'
    else:
        message = 'ç¼“å­˜å·²æ¸…ç†'

    return jsonify({
        'success': True,
        'message': message
    })

# æ·»åŠ  /upload åˆ«åè·¯ç”±ï¼ˆå…¼å®¹å‰ç«¯ï¼‰
@app.route('/upload', methods=['POST', 'OPTIONS'])
def upload_file_alias():
    """ä¸Šä¼ æ–‡ä»¶çš„åˆ«åè·¯ç”±"""
    return upload_file()

# æ·»åŠ ç®¡ç†å‘˜è®¾ç½®æ›´æ–° API
@app.route('/api/admin/settings', methods=['POST', 'OPTIONS'])
@admin_module.login_required
def admin_update_settings():
    """æ›´æ–°ç®¡ç†å‘˜è®¾ç½®"""
    data = request.get_json()
    new_username = data.get('username', '').strip()
    new_password = data.get('password', '').strip()

    if not new_username and not new_password:
        return jsonify({'success': False, 'message': 'è¯·æä¾›æ–°çš„ç”¨æˆ·åæˆ–å¯†ç '}), 400

    if new_username and len(new_username) < 3:
        return jsonify({'success': False, 'message': 'ç”¨æˆ·åè‡³å°‘éœ€è¦3ä¸ªå­—ç¬¦'}), 400

    if new_password and len(new_password) < 6:
        return jsonify({'success': False, 'message': 'å¯†ç è‡³å°‘éœ€è¦6ä¸ªå­—ç¬¦'}), 400

    if admin_module.update_admin_credentials(new_username, new_password):
        if new_username:
            session['admin_username'] = new_username

        return jsonify({
            'success': True,
            'message': 'è®¾ç½®æ›´æ–°æˆåŠŸ'
        })

    return jsonify({'success': False, 'message': 'æ›´æ–°å¤±è´¥'}), 500

# æ·»åŠ æ¸…ç†ç¼“å­˜åˆ«åï¼ˆå…¼å®¹å‰ç«¯ï¼‰
@app.route('/api/admin/clear-cache', methods=['POST', 'OPTIONS'])
@admin_module.login_required
def clear_cache_alias():
    """æ¸…ç†ç¼“å­˜çš„åˆ«åè·¯ç”±"""
    return clear_cache()

# ===================== Auth Token APIè·¯ç”± =====================
@app.route('/api/auth/token/generate', methods=['POST', 'OPTIONS'])
def generate_guest_token():
    """ç”Ÿæˆæ¸¸å®¢token"""
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return add_cache_headers(response, 'no-cache')

    try:
        # è·å–è¯·æ±‚ä¿¡æ¯
        ip_address = request.headers.get('X-Forwarded-For', request.remote_addr)
        user_agent = request.headers.get('User-Agent', '')

        # ä»è¯·æ±‚ä½“è·å–å¯é€‰å‚æ•°
        data = request.get_json() or {}
        upload_limit = data.get('upload_limit', 999999)  # é»˜è®¤æ— é™åˆ¶
        expires_days = data.get('expires_days', 36500)  # é»˜è®¤100å¹´
        description = data.get('description', 'æ¸¸å®¢Token')

        # ç§»é™¤å‚æ•°èŒƒå›´é™åˆ¶
        # upload_limit = min(max(upload_limit, 1), 1000)  # 1-1000å¼ 
        # expires_days = min(max(expires_days, 1), 365)   # 1-365å¤©

        # åˆ›å»ºtoken
        token = create_auth_token(
            ip_address=ip_address,
            user_agent=user_agent,
            description=description,
            upload_limit=upload_limit,
            expires_days=expires_days
        )

        if not token:
            response = jsonify({
                'success': False,
                'error': 'ç”ŸæˆTokenå¤±è´¥'
            })
            response.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(response, 'no-cache'), 500

        # è·å–tokenä¿¡æ¯
        token_info = get_token_info(token)

        response = jsonify({
            'success': True,
            'data': {
                'token': token,
                'upload_limit': upload_limit,
                'expires_days': expires_days,
                'expires_at': token_info['expires_at'] if token_info else None,
                'message': f'Tokenå·²ç”Ÿæˆï¼Œå¯ä¸Šä¼ {upload_limit}å¼ å›¾ç‰‡ï¼Œæœ‰æ•ˆæœŸ{expires_days}å¤©'
            }
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache')

    except Exception as e:
        logger.error(f"ç”Ÿæˆtokenå¤±è´¥: {e}")
        response = jsonify({
            'success': False,
            'error': str(e)
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

@app.route('/api/auth/token/verify', methods=['POST', 'OPTIONS'])
def verify_guest_token():
    """éªŒè¯tokenæ˜¯å¦æœ‰æ•ˆ"""
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        return add_cache_headers(response, 'no-cache')

    try:
        # ä»è¯·æ±‚å¤´æˆ–è¯·æ±‚ä½“è·å–token
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            data = request.get_json() or {}
            token = data.get('token', '')

        if not token:
            response = jsonify({
                'success': False,
                'valid': False,
                'error': 'æœªæä¾›Token'
            })
            response.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(response, 'no-cache'), 400

        # éªŒè¯token
        verification = verify_auth_token(token)

        if verification['valid']:
            token_data = verification['token_data']
            response = jsonify({
                'success': True,
                'valid': True,
                'data': {
                    'upload_count': token_data['upload_count'],
                    'upload_limit': token_data['upload_limit'],
                    'remaining_uploads': verification['remaining_uploads'],
                    'expires_at': token_data['expires_at'],
                    'created_at': token_data['created_at'],
                    'last_used': token_data['last_used']
                }
            })
        else:
            response = jsonify({
                'success': False,
                'valid': False,
                'reason': verification['reason']
            })

        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache')

    except Exception as e:
        logger.error(f"éªŒè¯tokenå¤±è´¥: {e}")
        response = jsonify({
            'success': False,
            'valid': False,
            'error': str(e)
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

@app.route('/api/auth/upload', methods=['POST', 'OPTIONS'])
def upload_with_token():
    """ä½¿ç”¨tokenä¸Šä¼ å›¾ç‰‡"""
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        return add_cache_headers(response, 'no-cache')

    global telegram_app

    if not telegram_app:
        response = jsonify({'success': False, 'error': 'Telegram botæœªåˆå§‹åŒ–'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

    # è·å–token
    token = request.headers.get('Authorization', '').replace('Bearer ', '')
    if not token:
        response = jsonify({'success': False, 'error': 'æœªæä¾›Token'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 401

    # éªŒè¯token
    verification = verify_auth_token(token)
    if not verification['valid']:
        response = jsonify({
            'success': False,
            'error': f"Tokenæ— æ•ˆ: {verification['reason']}"
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 401

    # æ£€æŸ¥æ–‡ä»¶
    if 'file' not in request.files:
        response = jsonify({'success': False, 'error': 'æœªæä¾›æ–‡ä»¶'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400

    file = request.files['file']
    if file.filename == '':
        response = jsonify({'success': False, 'error': 'æœªé€‰æ‹©æ–‡ä»¶'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400

    if not file.content_type.startswith('image/'):
        response = jsonify({'success': False, 'error': 'åªå…è®¸ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400

    file.seek(0, 2)
    file_size = file.tell()
    file.seek(0)

    if file_size > 20 * 1024 * 1024:
        response = jsonify({'success': False, 'error': 'æ–‡ä»¶å¤§å°è¶…è¿‡20MBé™åˆ¶'})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 400

    try:
        file_content = file.read()
        file.seek(0)

        # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        file_hash = hashlib.md5(file_content).hexdigest()

        # ä¸Šä¼ åˆ°Telegram
        if file_size <= 10 * 1024 * 1024:
            files = {'photo': (file.filename, file_content, file.content_type)}
            data = {
                'chat_id': STORAGE_CHAT_ID,
                'caption': f"æ¸¸å®¢ä¸Šä¼  | Token: {token[:20]}... | æ–‡ä»¶å: {file.filename} | å¤§å°: {file_size} bytes | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}"
            }
            response_tg = requests.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendPhoto",
                files=files, data=data, timeout=30
            )
        else:
            files = {'document': (file.filename, file_content, file.content_type)}
            data = {
                'chat_id': STORAGE_CHAT_ID,
                'caption': f"æ¸¸å®¢ä¸Šä¼ (å¤§æ–‡ä»¶) | Token: {token[:20]}... | æ–‡ä»¶å: {file.filename} | å¤§å°: {file_size} bytes | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}"
            }
            response_tg = requests.post(
                f"https://api.telegram.org/bot{BOT_TOKEN}/sendDocument",
                files=files, data=data, timeout=60
            )

        if not response_tg.ok:
            logger.error(f"Telegram APIé”™è¯¯: {response_tg.text}")
            resp = jsonify({'success': False, 'error': 'ä¸Šä¼ åˆ°Telegramå¤±è´¥'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500

        result = response_tg.json()
        if not result.get('ok'):
            logger.error(f"Telegram APIå¤±è´¥: {result}")
            resp = jsonify({'success': False, 'error': 'Telegram APIå¤±è´¥'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500

        # è·å–æ–‡ä»¶ä¿¡æ¯
        if file_size <= 10 * 1024 * 1024:
            photos = result['result']['photo']
            if not photos:
                resp = jsonify({'success': False, 'error': 'å“åº”ä¸­æ— å›¾ç‰‡'})
                resp.headers['Access-Control-Allow-Origin'] = '*'
                return add_cache_headers(resp, 'no-cache'), 500
            photo = photos[-1]
            file_id = photo['file_id']
        else:
            document = result['result']['document']
            if not document:
                resp = jsonify({'success': False, 'error': 'å“åº”ä¸­æ— æ–‡æ¡£'})
                resp.headers['Access-Control-Allow-Origin'] = '*'
                return add_cache_headers(resp, 'no-cache'), 500
            file_id = document['file_id']

        file_response = requests.get(
            f"https://api.telegram.org/bot{BOT_TOKEN}/getFile",
            params={'file_id': file_id}, timeout=30
        )

        if not file_response.ok:
            logger.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {file_response.text}")
            resp = jsonify({'success': False, 'error': 'è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500

        file_result = file_response.json()
        if not file_result.get('ok'):
            logger.error(f"è·å–æ–‡ä»¶APIå¤±è´¥: {file_result}")
            resp = jsonify({'success': False, 'error': 'è·å–æ–‡ä»¶APIå¤±è´¥'})
            resp.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(resp, 'no-cache'), 500

        file_path = file_result['result']['file_path']
        tg_file_size = file_result['result'].get('file_size', file_size)

        logger.info(f"Tokenä¸Šä¼ æˆåŠŸ: file_id={file_id}, token={token[:20]}..., size={tg_file_size}")

        encrypted_id = encrypt_file_id(file_id, file_path)
        mime_type = get_mime_type(file.filename)

        file_data = {
            'file_id': file_id,
            'file_path': file_path,
            'upload_time': int(time.time()),
            'user_id': 0,
            'username': 'guest_user',
            'file_size': tg_file_size,
            'source': 'guest_token',
            'original_filename': file.filename,
            'mime_type': mime_type,
            'file_hash': file_hash,
            'is_group_upload': 0,
            'auth_token': token
        }
        save_file_info(encrypted_id, file_data)

        # æ›´æ–°tokenä½¿ç”¨æ¬¡æ•°
        update_token_usage(token)

        # ç”ŸæˆURL
        base_url = get_domain(request)
        permanent_url = f"{base_url}/image/{encrypted_id}"

        # è·å–å‰©ä½™ä¸Šä¼ æ¬¡æ•°
        verification_after = verify_auth_token(token)
        remaining = verification_after.get('remaining_uploads', 0) if verification_after['valid'] else 0

        logger.info(f"æ¸¸å®¢ä¸Šä¼ å®Œæˆ: {file.filename} -> {encrypted_id}, å‰©ä½™: {remaining}æ¬¡")

        def format_size(size_bytes):
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            elif size_bytes < 1024 * 1024 * 1024:
                return f"{size_bytes / 1024 / 1024:.1f} MB"
            else:
                return f"{size_bytes / 1024 / 1024 / 1024:.1f} GB"

        resp = jsonify({
            'success': True,
            'data': {
                'url': permanent_url,
                'filename': file.filename,
                'size': format_size(tg_file_size),
                'upload_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'remaining_uploads': remaining
            }
        })

        resp.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(resp, 'no-cache')

    except Exception as e:
        logger.error(f"Tokenä¸Šä¼ é”™è¯¯: {e}")
        resp = jsonify({'success': False, 'error': str(e)})
        resp.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(resp, 'no-cache'), 500

@app.route('/api/auth/uploads', methods=['GET', 'OPTIONS'])
def get_token_uploads_api():
    """è·å–tokenä¸Šä¼ çš„å›¾ç‰‡åˆ—è¡¨"""
    if request.method == 'OPTIONS':
        response = make_response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
        return add_cache_headers(response, 'no-cache')

    try:
        # è·å–token
        token = request.headers.get('Authorization', '').replace('Bearer ', '')
        if not token:
            token = request.args.get('token', '')

        if not token:
            response = jsonify({
                'success': False,
                'error': 'æœªæä¾›Token'
            })
            response.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(response, 'no-cache'), 401

        # éªŒè¯token
        verification = verify_auth_token(token)
        if not verification['valid']:
            response = jsonify({
                'success': False,
                'error': f"Tokenæ— æ•ˆ: {verification['reason']}"
            })
            response.headers['Access-Control-Allow-Origin'] = '*'
            return add_cache_headers(response, 'no-cache'), 401

        # è·å–åˆ†é¡µå‚æ•°
        limit = request.args.get('limit', 50, type=int)
        page = request.args.get('page', 1, type=int)

        # è·å–ä¸Šä¼ åˆ—è¡¨
        uploads = get_token_uploads(token, limit, page)

        # æ ¼å¼åŒ–æ•°æ®
        base_url = get_domain(request)
        for upload in uploads:
            upload['image_url'] = f"{base_url}/image/{upload['encrypted_id']}"
            if upload.get('created_at'):
                try:
                    dt = datetime.fromisoformat(upload['created_at'].replace('Z', '+00:00'))
                    upload['created_at'] = dt.strftime('%Y-%m-%d %H:%M:%S')
                except:
                    pass

        # è·å–tokenä¿¡æ¯
        token_info = get_token_info(token)

        response = jsonify({
            'success': True,
            'data': {
                'uploads': uploads,
                'total_uploads': token_info['upload_count'] if token_info else 0,
                'upload_limit': token_info['upload_limit'] if token_info else 0,
                'remaining_uploads': verification['remaining_uploads'],
                'page': page,
                'limit': limit,
                'has_more': len(uploads) == limit
            }
        })

        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'private', 60)

    except Exception as e:
        logger.error(f"è·å–tokenä¸Šä¼ åˆ—è¡¨å¤±è´¥: {e}")
        response = jsonify({
            'success': False,
            'error': str(e)
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

# ===================== å…¬å‘Šç®¡ç†API =====================
@app.route('/api/announcement', methods=['GET', 'OPTIONS'])
def get_announcement():
    """è·å–å½“å‰å…¬å‘Š"""
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        return add_cache_headers(response, 'no-cache')

    try:
        conn = sqlite3.connect(DATABASE_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # è·å–æœ€æ–°çš„å…¬å‘Š
        cursor.execute('''
            SELECT id, enabled, content, created_at, updated_at
            FROM announcements
            ORDER BY id DESC
            LIMIT 1
        ''')

        announcement = cursor.fetchone()
        conn.close()

        if announcement:
            response = jsonify({
                'success': True,
                'data': {
                    'id': announcement['id'],
                    'enabled': bool(announcement['enabled']),
                    'content': announcement['content'],
                    'created_at': announcement['created_at'],
                    'updated_at': announcement['updated_at']
                }
            })
        else:
            response = jsonify({
                'success': True,
                'data': {
                    'id': 0,
                    'enabled': False,
                    'content': '',
                    'created_at': None,
                    'updated_at': None
                }
            })

        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache')

    except Exception as e:
        logger.error(f"è·å–å…¬å‘Šå¤±è´¥: {e}")
        response = jsonify({
            'success': False,
            'error': str(e)
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return add_cache_headers(response, 'no-cache'), 500

@app.route('/api/admin/announcement', methods=['GET', 'POST', 'OPTIONS'])
@admin_module.login_required
def admin_announcement():
    """ç®¡ç†å‘˜å…¬å‘Šç®¡ç†"""
    if request.method == 'OPTIONS':
        response = Response()
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
        response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
        response.headers['Access-Control-Allow-Credentials'] = 'true'
        return add_cache_headers(response, 'no-cache')

    try:
        conn = sqlite3.connect(DATABASE_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        if request.method == 'GET':
            # è·å–å…¬å‘Š
            cursor.execute('''
                SELECT id, enabled, content, created_at, updated_at
                FROM announcements
                ORDER BY id DESC
                LIMIT 1
            ''')

            announcement = cursor.fetchone()
            conn.close()

            if announcement:
                response = jsonify({
                    'success': True,
                    'data': {
                        'id': announcement['id'],
                        'enabled': bool(announcement['enabled']),
                        'content': announcement['content'],
                        'created_at': announcement['created_at'],
                        'updated_at': announcement['updated_at']
                    }
                })
            else:
                response = jsonify({
                    'success': True,
                    'data': {
                        'id': 0,
                        'enabled': False,
                        'content': '',
                        'created_at': None,
                        'updated_at': None
                    }
                })

        elif request.method == 'POST':
            # æ›´æ–°å…¬å‘Š
            data = request.get_json()
            enabled = data.get('enabled', True)
            content = data.get('content', '')

            # è·å–å½“å‰å…¬å‘Š
            cursor.execute('SELECT id, content FROM announcements ORDER BY id DESC LIMIT 1')
            result = cursor.fetchone()

            # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰å˜åŒ–
            content_changed = False
            if result:
                old_content = result['content']
                content_changed = (old_content != content)

            if result and not content_changed:
                # å†…å®¹æ²¡æœ‰å˜åŒ–ï¼Œåªæ›´æ–°å¯ç”¨çŠ¶æ€
                announcement_id = result['id']
                cursor.execute('''
                    UPDATE announcements
                    SET enabled = ?, updated_at = CURRENT_TIMESTAMP
                    WHERE id = ?
                ''', (enabled, announcement_id))
            else:
                # å†…å®¹æœ‰å˜åŒ–æˆ–æ²¡æœ‰å…¬å‘Šï¼Œåˆ›å»ºæ–°å…¬å‘Š
                # å…ˆç¦ç”¨æ‰€æœ‰æ—§å…¬å‘Š
                if result:
                    cursor.execute('UPDATE announcements SET enabled = 0')

                # åˆ›å»ºæ–°å…¬å‘Š
                cursor.execute('''
                    INSERT INTO announcements (enabled, content)
                    VALUES (?, ?)
                ''', (enabled, content))
                announcement_id = cursor.lastrowid

            conn.commit()
            conn.close()

            response = jsonify({
                'success': True,
                'message': 'å…¬å‘Šæ›´æ–°æˆåŠŸ',
                'data': {
                    'id': announcement_id,
                    'enabled': enabled,
                    'content': content
                }
            })

        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Credentials'] = 'true'
        return add_cache_headers(response, 'no-cache')

    except Exception as e:
        logger.error(f"å…¬å‘Šç®¡ç†å¤±è´¥: {e}")
        response = jsonify({
            'success': False,
            'error': str(e)
        })
        response.headers['Access-Control-Allow-Origin'] = request.headers.get('Origin', '*')
        response.headers['Access-Control-Allow-Credentials'] = 'true'
        return add_cache_headers(response, 'no-cache'), 500

# æ³¨å†Œç®¡ç†å‘˜è·¯ç”±
admin_module.register_admin_routes(app, DATABASE_PATH, lambda: get_stats()['total_files'],
                                 lambda: get_stats()['total_size'], add_cache_headers)

# ===================== SPAè·¯ç”±ï¼ˆå¿…é¡»åœ¨æ‰€æœ‰å…¶ä»–è·¯ç”±ä¹‹åæ³¨å†Œï¼‰ =====================
# æ•è·æ‰€æœ‰å‰ç«¯è·¯ç”±ï¼ˆSPAè·¯ç”±ï¼‰
@app.route('/<path:path>')
def catch_all(path):
    """æ•è·æ‰€æœ‰è·¯ç”±ï¼Œä¼˜å…ˆè¿”å›é™æ€æ–‡ä»¶ï¼Œå¦åˆ™è¿”å›200.htmlï¼ˆSPAï¼‰"""
    logger.info(f"[SPAè·¯ç”±] è¯·æ±‚è·¯å¾„: {path}")

    # å¦‚æœæ˜¯APIè·¯ç”±ï¼Œè·³è¿‡
    if path.startswith('api/') or path.startswith('image/') or path.startswith('upload'):
        logger.info(f"[SPAè·¯ç”±] APIè·¯ç”±ï¼Œè·³è¿‡: {path}")
        return jsonify({'error': 'Not found'}), 404

    # å°è¯•è¿”å›é™æ€æ–‡ä»¶
    file_path = os.path.join(STATIC_FOLDER, path)
    logger.info(f"[SPAè·¯ç”±] æ£€æŸ¥æ–‡ä»¶è·¯å¾„: {file_path}")

    # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥è¿”å›
    if os.path.exists(file_path) and os.path.isfile(file_path):
        logger.info(f"[SPAè·¯ç”±] æ‰¾åˆ°æ–‡ä»¶ï¼Œè¿”å›: {file_path}")
        return send_file(file_path)

    # å¦‚æœæ˜¯ç›®å½•ï¼Œå°è¯•è¿”å›ç›®å½•ä¸‹çš„index.html
    if os.path.exists(file_path) and os.path.isdir(file_path):
        index_in_dir = os.path.join(file_path, 'index.html')
        logger.info(f"[SPAè·¯ç”±] æ£€æŸ¥ç›®å½•index.html: {index_in_dir}")
        if os.path.exists(index_in_dir):
            logger.info(f"[SPAè·¯ç”±] æ‰¾åˆ°ç›®å½•index.htmlï¼Œè¿”å›: {index_in_dir}")
            return send_file(index_in_dir)

    # å¦åˆ™è¿”å›200.htmlï¼ˆNuxtç”Ÿæˆçš„SPAå›é€€é¡µé¢ï¼‰
    fallback_path = os.path.join(STATIC_FOLDER, '200.html')
    logger.info(f"[SPAè·¯ç”±] å°è¯•è¿”å›200.html: {fallback_path}")
    if os.path.exists(fallback_path):
        logger.info(f"[SPAè·¯ç”±] è¿”å›200.htmlä½œä¸ºSPAå›é€€")
        return send_file(fallback_path)

    # å¦‚æœ200.htmlä¸å­˜åœ¨ï¼Œå°è¯•è¿”å›index.html
    index_path = os.path.join(STATIC_FOLDER, 'index.html')
    logger.info(f"[SPAè·¯ç”±] å°è¯•è¿”å›index.html: {index_path}")
    if os.path.exists(index_path):
        logger.info(f"[SPAè·¯ç”±] è¿”å›index.html")
        return send_file(index_path)

    logger.warning(f"[SPAè·¯ç”±] æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…æ–‡ä»¶ï¼Œè¿”å›404: {path}")
    return jsonify({'error': 'Not found'}), 404

# ===================== è¾…åŠ©å‡½æ•° =====================
def encrypt_file_id(file_id: str, file_path: str) -> str:
    """åŠ å¯†æ–‡ä»¶IDï¼Œéšè—æ•æ„Ÿä¿¡æ¯"""
    data = f"{file_id}:{file_path}:{int(time.time())}"
    encoded = base64.b64encode(data.encode()).decode()
    hash_obj = hashlib.md5(f"{encoded}{SECRET_KEY}".encode())
    return f"{encoded[:16]}{hash_obj.hexdigest()[:8]}"

def get_mime_type(file_path: str) -> str:
    """æ ¹æ®æ–‡ä»¶æ‰©å±•åè·å–MIMEç±»å‹"""
    ext = Path(file_path).suffix.lower()
    mime_types = {
        '.jpg': 'image/jpeg',
        '.jpeg': 'image/jpeg',
        '.png': 'image/png',
        '.gif': 'image/gif',
        '.webp': 'image/webp',
        '.bmp': 'image/bmp',
        '.svg': 'image/svg+xml',
        '.ico': 'image/x-icon',
        '.tiff': 'image/tiff',
        '.tif': 'image/tiff'
    }
    return mime_types.get(ext, 'image/jpeg')

# ===================== Auth Token ç®¡ç†å‡½æ•° =====================
def generate_auth_token() -> str:
    """ç”Ÿæˆå”¯ä¸€çš„auth_token"""
    import secrets
    # ç”Ÿæˆ32å­—èŠ‚çš„éšæœºtokenï¼Œè½¬æ¢ä¸º64å­—ç¬¦çš„åå…­è¿›åˆ¶å­—ç¬¦ä¸²
    token = secrets.token_hex(32)
    return f"guest_{token}"

def create_auth_token(ip_address: str = None, user_agent: str = None,
                     description: str = None, upload_limit: int = 100,
                     expires_days: int = 30) -> Optional[str]:
    """åˆ›å»ºæ–°çš„auth_token"""
    try:
        token = generate_auth_token()
        expires_at = datetime.now() + timedelta(days=expires_days)

        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()

        cursor.execute('''
            INSERT INTO auth_tokens
            (token, expires_at, upload_limit, ip_address, user_agent, description)
            VALUES (?, ?, ?, ?, ?, ?)
        ''', (token, expires_at, upload_limit, ip_address, user_agent, description or 'æ¸¸å®¢Token'))

        conn.commit()
        conn.close()

        logger.info(f"åˆ›å»ºæ–°çš„auth_token: {token[:20]}... (é™åˆ¶: {upload_limit}å¼ , æœ‰æ•ˆæœŸ: {expires_days}å¤©)")
        return token

    except Exception as e:
        logger.error(f"åˆ›å»ºauth_tokenå¤±è´¥: {e}")
        return None

def verify_auth_token(token: str) -> Dict[str, Any]:
    """éªŒè¯auth_tokenæ˜¯å¦æœ‰æ•ˆ"""
    if not token:
        return {'valid': False, 'reason': 'Tokenä¸ºç©º'}

    try:
        conn = sqlite3.connect(DATABASE_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute('''
            SELECT * FROM auth_tokens WHERE token = ?
        ''', (token,))

        row = cursor.fetchone()
        conn.close()

        if not row:
            return {'valid': False, 'reason': 'Tokenä¸å­˜åœ¨'}

        token_data = dict(row)

        # æ£€æŸ¥æ˜¯å¦æ¿€æ´»
        if not token_data['is_active']:
            return {'valid': False, 'reason': 'Tokenå·²è¢«ç¦ç”¨'}

        # æ£€æŸ¥æ˜¯å¦è¿‡æœŸï¼ˆå·²ç§»é™¤æ—¶é—´é™åˆ¶æ£€æŸ¥ï¼‰
        # if token_data['expires_at']:
        #     expires_at = datetime.fromisoformat(token_data['expires_at'])
        #     if datetime.now() > expires_at:
        #         return {'valid': False, 'reason': 'Tokenå·²è¿‡æœŸ'}

        # æ£€æŸ¥ä¸Šä¼ é™åˆ¶ï¼ˆå·²ç§»é™¤ä¸Šä¼ æ•°é‡é™åˆ¶æ£€æŸ¥ï¼‰
        # if token_data['upload_count'] >= token_data['upload_limit']:
        #     return {'valid': False, 'reason': f"å·²è¾¾åˆ°ä¸Šä¼ é™åˆ¶({token_data['upload_limit']}å¼ )"}

        return {
            'valid': True,
            'token_data': token_data,
            'remaining_uploads': -1  # -1 è¡¨ç¤ºæ— é™åˆ¶
        }

    except Exception as e:
        logger.error(f"éªŒè¯auth_tokenå¤±è´¥: {e}")
        return {'valid': False, 'reason': 'éªŒè¯å¤±è´¥'}

def update_token_usage(token: str):
    """æ›´æ–°tokenä½¿ç”¨è®°å½•"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        cursor = conn.cursor()

        cursor.execute('''
            UPDATE auth_tokens
            SET upload_count = upload_count + 1,
                last_used = CURRENT_TIMESTAMP
            WHERE token = ?
        ''', (token,))

        conn.commit()
        conn.close()

    except Exception as e:
        logger.error(f"æ›´æ–°tokenä½¿ç”¨è®°å½•å¤±è´¥: {e}")

def get_token_info(token: str) -> Optional[Dict[str, Any]]:
    """è·å–tokenè¯¦ç»†ä¿¡æ¯"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        cursor.execute('''
            SELECT * FROM auth_tokens WHERE token = ?
        ''', (token,))

        row = cursor.fetchone()
        conn.close()

        return dict(row) if row else None

    except Exception as e:
        logger.error(f"è·å–tokenä¿¡æ¯å¤±è´¥: {e}")
        return None

def get_token_uploads(token: str, limit: int = 50, page: int = 1) -> List[Dict[str, Any]]:
    """è·å–tokenä¸Šä¼ çš„æ‰€æœ‰å›¾ç‰‡"""
    try:
        conn = sqlite3.connect(DATABASE_PATH)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        offset = (page - 1) * limit

        cursor.execute('''
            SELECT encrypted_id, original_filename, file_size, created_at,
                   cdn_cached, cdn_url, mime_type
            FROM file_storage
            WHERE auth_token = ?
            ORDER BY created_at DESC
            LIMIT ? OFFSET ?
        ''', (token, limit, offset))

        rows = cursor.fetchall()
        conn.close()

        return [dict(row) for row in rows]

    except Exception as e:
        logger.error(f"è·å–tokenä¸Šä¼ è®°å½•å¤±è´¥: {e}")
        return []

# ===================== Telegramå¤„ç†å‡½æ•° =====================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç† /start å‘½ä»¤"""
    stats = get_stats()
    
    cdn_info = ""
    if CDN_ENABLED and CLOUDFLARE_CDN_DOMAIN:
        cdn_info = f"\nğŸŒ *CDNåŸŸå:* `{CLOUDFLARE_CDN_DOMAIN}`"
    
    monitor_info = ""
    if CDN_MONITOR_ENABLED:
        monitor_info = f"\nğŸ“Š *CDNç›‘æ§:* å·²å¯ç”¨ (é˜Ÿåˆ—: {stats['cdn_stats']['monitor_queue_size']})"
    
    redirect_info = ""
    if CDN_REDIRECT_ENABLED:
        redirect_info = f"\nğŸ”„ *æ™ºèƒ½é‡å®šå‘:* å·²å¯ç”¨ (æœ€å¤§{CDN_REDIRECT_MAX_COUNT}æ¬¡)"
    
    group_upload_info = ""
    if ENABLE_GROUP_UPLOAD:
        group_upload_info = f"\nğŸ“¸ *ç¾¤ç»„ä¸Šä¼ :* å·²å¯ç”¨ (å·²ä¸Šä¼ : {stats['group_uploads']}å¼ )"
        if GROUP_UPLOAD_ADMIN_ONLY:
            group_upload_info += f"\nğŸ‘® *æƒé™æ§åˆ¶:* ä»…ç®¡ç†å‘˜"
    
    await update.message.reply_text(
        "â˜ï¸ *Telegram äº‘å›¾åºŠæœºå™¨äºº*\n\n"
        "âœ¨ *åŠŸèƒ½ç‰¹ç‚¹:*\n"
        "â€¢ ç›´æ¥å‘é€å›¾ç‰‡è·å–æ°¸ä¹…ç›´é“¾\n"
        "â€¢ åŸºäºTelegramäº‘å­˜å‚¨ï¼Œæ— éœ€æœ¬åœ°ç£ç›˜\n"
        "â€¢ æ”¯æŒWebç•Œé¢æ‹–æ‹½ä¸Šä¼ \n"
        "â€¢ æ”¯æŒæœ€å¤§20MBçš„å›¾ç‰‡æ–‡ä»¶\n"
        "â€¢ å®‰å…¨åŠ å¯†çš„é“¾æ¥åœ°å€\n"
        "â€¢ æ•°æ®åº“æŒä¹…åŒ–å­˜å‚¨\n"
        "â€¢ Cloudflare CDNå…¨çƒåŠ é€Ÿ\n"
        "â€¢ åç«¯è‡ªåŠ¨CDNç¼“å­˜æ£€æµ‹\n"
        "â€¢ æ™ºèƒ½CDNé‡å®šå‘ä¼˜åŒ–\n"
        "â€¢ é‡å®šå‘å¾ªç¯ä¿æŠ¤\n"
        "â€¢ è‡ªåŠ¨åˆ·æ–°è¿‡æœŸæ–‡ä»¶è·¯å¾„\n"
        "â€¢ æ–°æ–‡ä»¶å»¶è¿Ÿé‡å®šå‘ä¿æŠ¤\n"
        "â€¢ ç¾¤ç»„å›¾ç‰‡è‡ªåŠ¨æ”¶å½•\n\n"
        f"ğŸŒ *Webç•Œé¢:* {get_domain(None)}\n"
        f"ğŸ”§ *ç®¡ç†åå°:* {get_domain(None)}/admin\n"
        f"ğŸ“¡ *æœåŠ¡å™¨IP:* {LOCAL_IP}:{PORT}\n"
        f"{cdn_info}\n"
        f"{monitor_info}\n"
        f"{redirect_info}\n"
        f"{group_upload_info}\n"
        f"ğŸ“Š *å·²å­˜å‚¨:* {stats['total_files']} ä¸ªæ–‡ä»¶\n"
        f"ğŸ’¾ *æ€»å¤§å°:* {stats['total_size'] / 1024 / 1024:.1f} MB\n"
        f"ğŸš€ *CDNçŠ¶æ€:* {'Cloudflareå·²å¯ç”¨' if CLOUDFLARE_CDN_DOMAIN else ('å·²å¯ç”¨' if CDN_ENABLED else 'æœªå¯ç”¨')}\n"
        f"ğŸ“¦ *æœ€å¤§æ–‡ä»¶:* 20MB\n\n"
        "ç›´æ¥å‘é€å›¾ç‰‡å³å¯å¼€å§‹ä½¿ç”¨ï¼",
        parse_mode='Markdown'
    )

async def handle_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†å›¾ç‰‡ä¸Šä¼ """
    user_id = update.effective_user.id
    username = update.effective_user.username or "æœªçŸ¥ç”¨æˆ·"
    
    msg = await update.message.reply_text("â³ æ­£åœ¨å¤„ç†å›¾ç‰‡...")
    
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡æ¡£ï¼ˆå¤§å›¾ç‰‡ï¼‰
        if update.message.document and update.message.document.mime_type.startswith('image/'):
            # å¤„ç†ä½œä¸ºæ–‡æ¡£å‘é€çš„å¤§å›¾ç‰‡
            document = update.message.document
            file_info = await context.bot.get_file(document.file_id)
            
            logger.info(f"ç”¨æˆ· {username}({user_id}) ä¸Šä¼ å¤§å›¾ç‰‡: file_id={document.file_id}, file_path={file_info.file_path}, size={document.file_size}")
            
            try:
                await context.bot.send_document(
                    chat_id=STORAGE_CHAT_ID,
                    document=document.file_id,
                    caption=f"ç”¨æˆ·: {username}({user_id}) | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')} | æ¥æº: æœºå™¨äºº | å¤§æ–‡ä»¶"
                )
                logger.info(f"å¤§å›¾ç‰‡å·²å¤‡ä»½åˆ°å­˜å‚¨ç¾¤ç»„: {document.file_id}")
            except Exception as e:
                logger.warning(f"Failed to backup to storage chat: {e}")
            
            encrypted_id = encrypt_file_id(document.file_id, file_info.file_path)
            
            file_data = {
                'file_id': document.file_id,
                'file_path': file_info.file_path,
                'upload_time': int(time.time()),
                'user_id': user_id,
                'username': username,
                'file_size': document.file_size,
                'source': 'telegram_bot',
                'original_filename': document.file_name or 'large_image.jpg',
                'mime_type': document.mime_type or 'image/jpeg',
                'is_group_upload': 0
            }
            save_file_info(encrypted_id, file_data)
            
            permanent_url = f"{get_domain(None)}/image/{encrypted_id}"
            cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}" if CLOUDFLARE_CDN_DOMAIN else None
            
            message_text = (
                f"âœ… *ä¸Šä¼ æˆåŠŸï¼*\n\n"
                f"ğŸ”— *æ°¸ä¹…ç›´é“¾:*\n`{permanent_url}`\n"
            )
            
            if cdn_url:
                message_text += f"\nğŸŒ *CDNåŠ é€Ÿ:*\n`{cdn_url}`\n"
            
            message_text += (
                f"\nğŸ“Š *æ–‡ä»¶ä¿¡æ¯:*\n"
                f"â€¢ å¤§å°: {document.file_size} bytes ({document.file_size / 1024 / 1024:.1f} MB)\n"
                f"â€¢ æ ¼å¼: {Path(document.file_name or 'image').suffix.upper()}\n"
                f"â€¢ ID: `{encrypted_id[:12]}...`\n"
                f"â€¢ å­˜å‚¨: Telegramäº‘ç«¯ + æ•°æ®åº“\n"
                f"â€¢ CDN: {'ç›‘æ§ä¸­' if CDN_MONITOR_ENABLED else ('å·²ç¼“å­˜' if CDN_ENABLED else 'æœªå¯ç”¨')}\n"
                f"â€¢ ç±»å‹: å¤§æ–‡ä»¶\n\n"
                f"ğŸ’¡ *æç¤º:* é“¾æ¥æ°¸ä¹…æœ‰æ•ˆï¼ŒCDNæ­£åœ¨åå°è‡ªåŠ¨ç¼“å­˜"
            )
            
            await msg.edit_text(message_text, parse_mode='Markdown')
            
        elif update.message.photo:
            # å¤„ç†æ™®é€šå›¾ç‰‡ï¼ˆ10MBä»¥ä¸‹ï¼‰
            photo = update.message.photo[-1]
            file_info = await context.bot.get_file(photo.file_id)
            
            logger.info(f"ç”¨æˆ· {username}({user_id}) ä¸Šä¼ å›¾ç‰‡: file_id={photo.file_id}, file_path={file_info.file_path}")
            
            try:
                await context.bot.send_photo(
                    chat_id=STORAGE_CHAT_ID,
                    photo=photo.file_id,
                    caption=f"ç”¨æˆ·: {username}({user_id}) | æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')} | æ¥æº: æœºå™¨äºº"
                )
                logger.info(f"å›¾ç‰‡å·²å¤‡ä»½åˆ°å­˜å‚¨ç¾¤ç»„: {photo.file_id}")
            except Exception as e:
                logger.warning(f"Failed to backup to storage chat: {e}")
            
            encrypted_id = encrypt_file_id(photo.file_id, file_info.file_path)
            
            file_data = {
                'file_id': photo.file_id,
                'file_path': file_info.file_path,
                'upload_time': int(time.time()),
                'user_id': user_id,
                'username': username,
                'file_size': file_info.file_size,
                'source': 'telegram_bot',
                'mime_type': get_mime_type(file_info.file_path),
                'is_group_upload': 0
            }
            save_file_info(encrypted_id, file_data)
            
            permanent_url = f"{get_domain(None)}/image/{encrypted_id}"
            cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}" if CLOUDFLARE_CDN_DOMAIN else None
            
            message_text = (
                f"âœ… *ä¸Šä¼ æˆåŠŸï¼*\n\n"
                f"ğŸ”— *æ°¸ä¹…ç›´é“¾:*\n`{permanent_url}`\n"
            )
            
            if cdn_url:
                message_text += f"\nğŸŒ *CDNåŠ é€Ÿ:*\n`{cdn_url}`\n"
            
            message_text += (
                f"\nğŸ“Š *æ–‡ä»¶ä¿¡æ¯:*\n"
                f"â€¢ å¤§å°: {file_info.file_size} bytes\n"
                f"â€¢ æ ¼å¼: {Path(file_info.file_path).suffix.upper()}\n"
                f"â€¢ ID: `{encrypted_id[:12]}...`\n"
                f"â€¢ å­˜å‚¨: Telegramäº‘ç«¯ + æ•°æ®åº“\n"
                f"â€¢ CDN: {'ç›‘æ§ä¸­' if CDN_MONITOR_ENABLED else ('å·²ç¼“å­˜' if CDN_ENABLED else 'æœªå¯ç”¨')}\n\n"
                f"ğŸ’¡ *æç¤º:* é“¾æ¥æ°¸ä¹…æœ‰æ•ˆï¼ŒCDNæ­£åœ¨åå°è‡ªåŠ¨ç¼“å­˜"
            )
            
            await msg.edit_text(message_text, parse_mode='Markdown')
        else:
            await msg.edit_text("âŒ è¯·å‘é€å›¾ç‰‡æ–‡ä»¶")
            return
            
        logger.info(f"å›¾ç‰‡å¤„ç†å®Œæˆ: {encrypted_id}")
        
    except Exception as e:
        logger.error(f"Error processing photo: {e}")
        await msg.edit_text("âŒ å¤„ç†å¤±è´¥ï¼Œè¯·é‡è¯•")

async def handle_group_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†ç¾¤ç»„ä¸­çš„å›¾ç‰‡ï¼ˆéæœºå™¨äººå‘é€ï¼‰"""
    if not ENABLE_GROUP_UPLOAD:
        return
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å­˜å‚¨ç¾¤ç»„ä¸­
    if update.effective_chat.id != STORAGE_CHAT_ID:
        return
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœºå™¨äººè‡ªå·±å‘çš„æ¶ˆæ¯ï¼ˆé¿å…å¤„ç†è‡ªå·±å‘é€çš„å¤‡ä»½å›¾ç‰‡ï¼‰
    if update.effective_user.is_bot:
        return
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœºå™¨äººè‡ªå·±
    global bot_info
    if bot_info and update.effective_user.id == bot_info.id:
        return
    
    user_id = update.effective_user.id
    username = update.effective_user.username or update.effective_user.first_name or "æœªçŸ¥ç”¨æˆ·"
    
    # æ£€æŸ¥æƒé™
    if GROUP_UPLOAD_ADMIN_ONLY and GROUP_ADMIN_ID_LIST:
        if user_id not in GROUP_ADMIN_ID_LIST:
            logger.info(f"éç®¡ç†å‘˜ç”¨æˆ· {username}({user_id}) åœ¨ç¾¤ç»„ä¸­å‘é€å›¾ç‰‡ï¼Œè·³è¿‡å¤„ç†")
            return
    
    try:
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–‡æ¡£ï¼ˆå¤§å›¾ç‰‡ï¼‰
        if update.message.document and update.message.document.mime_type.startswith('image/'):
            # å¤„ç†ä½œä¸ºæ–‡æ¡£å‘é€çš„å¤§å›¾ç‰‡
            document = update.message.document
            file_info = await context.bot.get_file(document.file_id)
            
            logger.info(f"ç¾¤ç»„ç”¨æˆ· {username}({user_id}) ä¸Šä¼ å¤§å›¾ç‰‡: file_id={document.file_id}, size={document.file_size}")
            
            encrypted_id = encrypt_file_id(document.file_id, file_info.file_path)
            
            file_data = {
                'file_id': document.file_id,
                'file_path': file_info.file_path,
                'upload_time': int(time.time()),
                'user_id': user_id,
                'username': username,
                'file_size': document.file_size,
                'source': 'telegram_group',
                'original_filename': document.file_name or f'group_image_{int(time.time())}.jpg',
                'mime_type': document.mime_type or 'image/jpeg',
                'is_group_upload': 1,
                'group_message_id': update.message.message_id
            }
            save_file_info(encrypted_id, file_data)
            
            # ç”Ÿæˆé“¾æ¥
            permanent_url = f"{get_domain(None)}/image/{encrypted_id}"
            cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}" if CLOUDFLARE_CDN_DOMAIN else None
            
            # å¦‚æœå¯ç”¨äº†å›å¤
            if GROUP_UPLOAD_REPLY:
                reply_text = f"âœ… *å›¾ç‰‡å·²æ”¶å½•*\n\n"
                
                if cdn_url and file_data.get('cdn_cached'):
                    reply_text += f"ğŸŒ *CDNé“¾æ¥:*\n`{cdn_url}`\n"
                else:
                    reply_text += f"ğŸ”— *ç›´é“¾:*\n`{permanent_url}`\n"
                    if cdn_url:
                        reply_text += f"\nâ³ *CDNç¼“å­˜ä¸­...*"
                
                reply_text += (
                    f"\nğŸ“Š *æ–‡ä»¶ä¿¡æ¯:*\n"
                    f"â€¢ å¤§å°: {document.file_size / 1024 / 1024:.1f} MB\n"
                    f"â€¢ ID: `{encrypted_id[:12]}...`\n"
                )
                
                reply_msg = await update.message.reply_text(
                    reply_text,
                    parse_mode='Markdown',
                    disable_web_page_preview=True
                )
                
                # å¦‚æœè®¾ç½®äº†åˆ é™¤å»¶è¿Ÿ
                if GROUP_UPLOAD_DELETE_DELAY > 0:
                    await asyncio.sleep(GROUP_UPLOAD_DELETE_DELAY)
                    try:
                        await reply_msg.delete()
                    except:
                        pass
            
            logger.info(f"ç¾¤ç»„å¤§å›¾ç‰‡å¤„ç†å®Œæˆ: {encrypted_id}")
            
        elif update.message.photo:
            # å¤„ç†æ™®é€šå›¾ç‰‡
            photo = update.message.photo[-1]
            file_info = await context.bot.get_file(photo.file_id)
            
            logger.info(f"ç¾¤ç»„ç”¨æˆ· {username}({user_id}) ä¸Šä¼ å›¾ç‰‡: file_id={photo.file_id}")
            
            encrypted_id = encrypt_file_id(photo.file_id, file_info.file_path)
            
            file_data = {
                'file_id': photo.file_id,
                'file_path': file_info.file_path,
                'upload_time': int(time.time()),
                'user_id': user_id,
                'username': username,
                'file_size': file_info.file_size,
                'source': 'telegram_group',
                'original_filename': f'group_image_{int(time.time())}.jpg',
                'mime_type': get_mime_type(file_info.file_path),
                'is_group_upload': 1,
                'group_message_id': update.message.message_id
            }
            save_file_info(encrypted_id, file_data)
            
            # ç”Ÿæˆé“¾æ¥
            permanent_url = f"{get_domain(None)}/image/{encrypted_id}"
            cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}" if CLOUDFLARE_CDN_DOMAIN else None
            
            # å¦‚æœå¯ç”¨äº†å›å¤
            if GROUP_UPLOAD_REPLY:
                reply_text = f"âœ… *å›¾ç‰‡å·²æ”¶å½•*\n\n"
                
                if cdn_url and file_data.get('cdn_cached'):
                    reply_text += f"ğŸŒ *CDNé“¾æ¥:*\n`{cdn_url}`\n"
                else:
                    reply_text += f"ğŸ”— *ç›´é“¾:*\n`{permanent_url}`\n"
                    if cdn_url:
                        reply_text += f"\nâ³ *CDNç¼“å­˜ä¸­...*"
                
                reply_text += (
                    f"\nğŸ“Š *æ–‡ä»¶ä¿¡æ¯:*\n"
                    f"â€¢ å¤§å°: {file_info.file_size / 1024:.1f} KB\n"
                    f"â€¢ ID: `{encrypted_id[:12]}...`\n"
                )
                
                reply_msg = await update.message.reply_text(
                    reply_text,
                    parse_mode='Markdown',
                    disable_web_page_preview=True
                )
                
                # å¦‚æœè®¾ç½®äº†åˆ é™¤å»¶è¿Ÿ
                if GROUP_UPLOAD_DELETE_DELAY > 0:
                    await asyncio.sleep(GROUP_UPLOAD_DELETE_DELAY)
                    try:
                        await reply_msg.delete()
                    except:
                        pass
            
            logger.info(f"ç¾¤ç»„å›¾ç‰‡å¤„ç†å®Œæˆ: {encrypted_id}")
            
    except Exception as e:
        logger.error(f"å¤„ç†ç¾¤ç»„å›¾ç‰‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

async def wait_for_cdn_cache(encrypted_id: str, cdn_url: str, timeout: int = 30) -> bool:
    """ç­‰å¾…CDNç¼“å­˜å®Œæˆ"""
    if not CLOUDFLARE_CDN_DOMAIN:
        return False
    
    # è§¦å‘CDNé¢„çƒ­
    if ENABLE_CACHE_WARMING:
        logger.info(f"å¼€å§‹CDNé¢„çƒ­: {encrypted_id}")
        await asyncio.sleep(CACHE_WARMING_DELAY)
        await cloudflare_cdn.warm_cache(cdn_url, encrypted_id)
        await asyncio.sleep(3)  # ç»™CDNä¸€ç‚¹æ—¶é—´å¤„ç†
    
    # ç­‰å¾…ç¼“å­˜å®Œæˆ
    start_time = time.time()
    check_interval = 2
    check_count = 0
    
    while time.time() - start_time < timeout:
        if cloudflare_cdn.check_cdn_status(encrypted_id):
            update_cdn_cache_status(encrypted_id, True)
            logger.info(f"CDNç¼“å­˜æˆåŠŸ: {encrypted_id} (ç¬¬{check_count + 1}æ¬¡æ£€æŸ¥)")
            return True
        
        check_count += 1
        await asyncio.sleep(check_interval)
        logger.debug(f"ç­‰å¾…CDNç¼“å­˜: {encrypted_id} (ç¬¬{check_count}æ¬¡æ£€æŸ¥)")
    
    logger.warning(f"CDNç¼“å­˜è¶…æ—¶: {encrypted_id} (å…±æ£€æŸ¥{check_count}æ¬¡)")
    return False

async def handle_group_photo(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†ç¾¤ç»„ä¸­çš„å›¾ç‰‡ï¼ˆéæœºå™¨äººå‘é€ï¼‰"""
    if not ENABLE_GROUP_UPLOAD:
        return
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å­˜å‚¨ç¾¤ç»„ä¸­
    if update.effective_chat.id != STORAGE_CHAT_ID:
        return
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœºå™¨äººè‡ªå·±å‘çš„æ¶ˆæ¯ï¼ˆé¿å…å¤„ç†è‡ªå·±å‘é€çš„å¤‡ä»½å›¾ç‰‡ï¼‰
    if update.effective_user.is_bot:
        return
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯æœºå™¨äººè‡ªå·±
    global bot_info
    if bot_info and update.effective_user.id == bot_info.id:
        return
    
    user_id = update.effective_user.id
    username = update.effective_user.username or update.effective_user.first_name or "æœªçŸ¥ç”¨æˆ·"
    
    # æ£€æŸ¥æƒé™
    if GROUP_UPLOAD_ADMIN_ONLY and GROUP_ADMIN_ID_LIST:
        if user_id not in GROUP_ADMIN_ID_LIST:
            logger.info(f"éç®¡ç†å‘˜ç”¨æˆ· {username}({user_id}) åœ¨ç¾¤ç»„ä¸­å‘é€å›¾ç‰‡ï¼Œè·³è¿‡å¤„ç†")
            return
    
    try:
        file_id = None
        file_path = None
        file_size = 0
        file_name = None
        mime_type = None
        is_document = False
        
        # åˆ¤æ–­æ˜¯æ–‡æ¡£è¿˜æ˜¯å›¾ç‰‡
        if update.message.document and update.message.document.mime_type.startswith('image/'):
            # å¤„ç†ä½œä¸ºæ–‡æ¡£å‘é€çš„å¤§å›¾ç‰‡
            document = update.message.document
            file_info = await context.bot.get_file(document.file_id)
            file_id = document.file_id
            file_path = file_info.file_path
            file_size = document.file_size
            file_name = document.file_name
            mime_type = document.mime_type
            is_document = True
            logger.info(f"ç¾¤ç»„ç”¨æˆ· {username}({user_id}) ä¸Šä¼ å¤§å›¾ç‰‡: file_id={file_id}, size={file_size}")
        elif update.message.photo:
            # å¤„ç†æ™®é€šå›¾ç‰‡
            photo = update.message.photo[-1]
            file_info = await context.bot.get_file(photo.file_id)
            file_id = photo.file_id
            file_path = file_info.file_path
            file_size = file_info.file_size
            mime_type = get_mime_type(file_path)
            logger.info(f"ç¾¤ç»„ç”¨æˆ· {username}({user_id}) ä¸Šä¼ å›¾ç‰‡: file_id={file_id}")
        else:
            return
        
        # ç”ŸæˆåŠ å¯†ID
        encrypted_id = encrypt_file_id(file_id, file_path)
        
        # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
        file_data = {
            'file_id': file_id,
            'file_path': file_path,
            'upload_time': int(time.time()),
            'user_id': user_id,
            'username': username,
            'file_size': file_size,
            'source': 'telegram_group',
            'original_filename': file_name or f'group_image_{int(time.time())}.jpg',
            'mime_type': mime_type or 'image/jpeg',
            'is_group_upload': 1,
            'group_message_id': update.message.message_id
        }
        save_file_info(encrypted_id, file_data)
        
        # ç”Ÿæˆé“¾æ¥
        cdn_url = f"https://{CLOUDFLARE_CDN_DOMAIN}/image/{encrypted_id}" if CLOUDFLARE_CDN_DOMAIN else None
        
        # å¦‚æœå¯ç”¨äº†å›å¤ä¸”æœ‰CDN
        if GROUP_UPLOAD_REPLY and cdn_url:
            # ç­‰å¾…CDNç¼“å­˜å®Œæˆ
            is_cached = await wait_for_cdn_cache(encrypted_id, cdn_url, timeout=30)
            
            # åªæœ‰åœ¨CDNç¼“å­˜æˆåŠŸåæ‰å‘é€å›å¤
            if is_cached:
                # æ„å»ºå›å¤æ–‡æœ¬
                reply_text = f"âœ… å›¾ç‰‡å·²æ”¶å½•\n\nğŸŒ {cdn_url}"
                
                # å‘é€å›å¤
                reply_msg = await update.message.reply_text(
                    reply_text,
                    disable_web_page_preview=False  # æ˜¾ç¤ºé“¾æ¥é¢„è§ˆ
                )
                
                # å¦‚æœè®¾ç½®äº†åˆ é™¤å»¶è¿Ÿ
                if GROUP_UPLOAD_DELETE_DELAY > 0:
                    await asyncio.sleep(GROUP_UPLOAD_DELETE_DELAY)
                    try:
                        await reply_msg.delete()
                    except Exception as e:
                        logger.debug(f"åˆ é™¤å›å¤æ¶ˆæ¯å¤±è´¥: {e}")
                
                # è®°å½•æˆåŠŸä¿¡æ¯
                file_type = "å¤§å›¾ç‰‡" if is_document else "å›¾ç‰‡"
                logger.info(f"ç¾¤ç»„{file_type}å¤„ç†å®Œæˆå¹¶å·²ç¼“å­˜: {encrypted_id}")
            else:
                # CDNé¢„çƒ­å¤±è´¥
                logger.warning(f"CDNé¢„çƒ­å¤±è´¥ï¼Œä¸å‘é€å›å¤: {encrypted_id}")
                # å¦‚æœCDNé¢„çƒ­å¤±è´¥ï¼Œä»ç„¶å°†ä»»åŠ¡åŠ å…¥ç›‘æ§é˜Ÿåˆ—
                if CDN_MONITOR_ENABLED:
                    add_to_cdn_monitor(encrypted_id, file_data['upload_time'])
                    logger.info(f"å·²å°† {encrypted_id} åŠ å…¥CDNç›‘æ§é˜Ÿåˆ—")
        else:
            # æ²¡æœ‰å¯ç”¨å›å¤æˆ–æ²¡æœ‰CDN
            if not GROUP_UPLOAD_REPLY:
                logger.info(f"ç¾¤ç»„å›¾ç‰‡å¤„ç†å®Œæˆ(æœªå¯ç”¨å›å¤): {encrypted_id}")
            elif not cdn_url:
                logger.info(f"ç¾¤ç»„å›¾ç‰‡å¤„ç†å®Œæˆ(æ— CDNé…ç½®): {encrypted_id}")
            
            # å³ä½¿ä¸å›å¤ï¼Œä¹Ÿè¦åŠ å…¥CDNç›‘æ§
            if CDN_MONITOR_ENABLED and CLOUDFLARE_CDN_DOMAIN:
                add_to_cdn_monitor(encrypted_id, file_data['upload_time'])
            
    except Exception as e:
        logger.error(f"å¤„ç†ç¾¤ç»„å›¾ç‰‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
# ===================== å‰ç«¯è‡ªåŠ¨å¯åŠ¨ï¼ˆå¼€å‘ï¼‰ =====================
frontend_process = None

def is_port_in_use(port: int) -> bool:
    try:
        with socket.create_connection(("127.0.0.1", port), timeout=0.5):
            return True
    except Exception:
        return False

def wait_for_port(port: int, timeout: int = 30) -> bool:
    start = time.time()
    while time.time() - start < timeout:
        if is_port_in_use(port):
            return True
        time.sleep(0.5)
    return is_port_in_use(port)

def ensure_frontend_dependencies() -> bool:
    if not os.path.isdir(FRONTEND_DIR):
        logger.warning(f"æœªæ‰¾åˆ°å‰ç«¯ç›®å½•: {FRONTEND_DIR}")
        return False
    npm_path = shutil.which("npm")
    if npm_path is None:
        logger.warning("æœªæ£€æµ‹åˆ° npmï¼Œè·³è¿‡è‡ªåŠ¨å¯åŠ¨å‰ç«¯ã€‚è¯·å®‰è£… Node.js æˆ–æ‰‹åŠ¨è¿è¡Œ npm run dev")
        return False
    node_modules_dir = os.path.join(FRONTEND_DIR, "node_modules")
    need_install = not os.path.isdir(node_modules_dir)

    # æ£€æŸ¥å¿…é¡»çš„å›¾æ ‡åŒ…æ˜¯å¦å­˜åœ¨
    required_pkgs = [
        os.path.join(node_modules_dir, "@iconify-json", "heroicons"),
        os.path.join(node_modules_dir, "@iconify-json", "heroicons-outline"),
        os.path.join(node_modules_dir, "@iconify-json", "heroicons-solid"),
        os.path.join(node_modules_dir, "@iconify-json", "lucide")
    ]
    for pkg in required_pkgs:
        if not os.path.isdir(pkg):
            need_install = True
            break

    if need_install:
        logger.info("æ­£åœ¨å®‰è£…/ä¿®å¤å‰ç«¯ä¾èµ– (npm install)...")
        try:
            subprocess.check_call([npm_path, "install"], cwd=FRONTEND_DIR)
        except subprocess.CalledProcessError as e:
            logger.error(f"å‰ç«¯ä¾èµ–å®‰è£…å¤±è´¥: {e}")
            return False
    return True

def check_and_fix_icon_format():
    """æ£€æŸ¥å¹¶ä¿®å¤å‰ç«¯Vueæ–‡ä»¶ä¸­çš„å›¾æ ‡æ ¼å¼é—®é¢˜"""
    import re

    logger.info("æ­£åœ¨æ£€æŸ¥å‰ç«¯å›¾æ ‡æ ¼å¼...")

    # éœ€è¦æ£€æŸ¥çš„ç›®å½•
    check_dirs = [
        os.path.join(FRONTEND_DIR, "pages"),
        os.path.join(FRONTEND_DIR, "layouts"),
        os.path.join(FRONTEND_DIR, "components")
    ]

    fixed_files = []
    total_fixes = 0

    # é”™è¯¯çš„å›¾æ ‡æ ¼å¼æ¨¡å¼
    wrong_patterns = [
        (r'name="i-heroicons-([^"]+)"', r'name="heroicons:\1"'),  # UIconç»„ä»¶
        (r"name='i-heroicons-([^']+)'", r"name='heroicons:\1'"),  # UIconç»„ä»¶ï¼ˆå•å¼•å·ï¼‰
        (r'icon="i-heroicons-([^"]+)"', r'icon="heroicons:\1"'),  # UButton/UInputçš„iconå±æ€§
        (r"icon='i-heroicons-([^']+)'", r"icon='heroicons:\1'"),  # UButton/UInputçš„iconå±æ€§ï¼ˆå•å¼•å·ï¼‰
    ]

    for check_dir in check_dirs:
        if not os.path.exists(check_dir):
            continue

        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰.vueæ–‡ä»¶
        for root, dirs, files in os.walk(check_dir):
            for file in files:
                if not file.endswith('.vue'):
                    continue

                file_path = os.path.join(root, file)
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()

                    original_content = content
                    file_fixed = False
                    fixes_in_file = 0

                    # åº”ç”¨æ‰€æœ‰ä¿®å¤æ¨¡å¼
                    for wrong_pattern, correct_pattern in wrong_patterns:
                        matches = re.findall(wrong_pattern, content)
                        if matches:
                            content = re.sub(wrong_pattern, correct_pattern, content)
                            fixes_in_file += len(matches)
                            file_fixed = True

                    # å¦‚æœæœ‰ä¿®æ”¹ï¼Œå†™å›æ–‡ä»¶
                    if file_fixed and content != original_content:
                        with open(file_path, 'w', encoding='utf-8') as f:
                            f.write(content)

                        relative_path = os.path.relpath(file_path, FRONTEND_DIR)
                        fixed_files.append(relative_path)
                        total_fixes += fixes_in_file
                        logger.info(f"  âœ“ ä¿®å¤ {relative_path} ({fixes_in_file}å¤„)")

                except Exception as e:
                    logger.warning(f"æ£€æŸ¥æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")

    if fixed_files:
        logger.info(f"å›¾æ ‡æ ¼å¼æ£€æŸ¥å®Œæˆ: ä¿®å¤äº† {len(fixed_files)} ä¸ªæ–‡ä»¶ï¼Œå…± {total_fixes} å¤„å›¾æ ‡æ ¼å¼é—®é¢˜")
        return True
    else:
        logger.info("å›¾æ ‡æ ¼å¼æ£€æŸ¥å®Œæˆ: æœªå‘ç°éœ€è¦ä¿®å¤çš„é—®é¢˜")
        return True

def start_frontend():
    global frontend_process
    if frontend_process is not None and frontend_process.poll() is None:
        logger.info("å‰ç«¯å¼€å‘æœåŠ¡å™¨å·²åœ¨è¿è¡Œ")
        return
    if is_port_in_use(FRONTEND_PORT):
        logger.info(f"æ£€æµ‹åˆ°å‰ç«¯ç«¯å£ {FRONTEND_PORT} å·²è¢«å ç”¨ï¼Œå‡å®š Nuxt å¼€å‘æœåŠ¡å·²è¿è¡Œï¼Œè·³è¿‡å¯åŠ¨")
        return
    if not ensure_frontend_dependencies():
        return

    # æ£€æŸ¥å¹¶ä¿®å¤å›¾æ ‡æ ¼å¼
    check_and_fix_icon_format()
    logger.info(f"å¯åŠ¨å‰ç«¯å¼€å‘æœåŠ¡å™¨: {FRONTEND_DEV_CMD} (cwd={FRONTEND_DIR})")
    creationflags = 0
    preexec_fn = None
    if sys.platform == 'win32':
        creationflags = subprocess.CREATE_NEW_PROCESS_GROUP
    else:
        import os as _os
        preexec_fn = _os.setsid
    try:
        frontend_process = subprocess.Popen(
            FRONTEND_DEV_CMD,
            cwd=FRONTEND_DIR,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            creationflags=creationflags,
            preexec_fn=preexec_fn,
            text=True,
            bufsize=1
        )
        atexit.register(stop_frontend)
        # å¼‚æ­¥è¯»å–éƒ¨åˆ†è¾“å‡ºï¼Œä¾¿äºè°ƒè¯•
        threading.Thread(target=_stream_frontend_output, args=(frontend_process,), daemon=True).start()
        if wait_for_port(FRONTEND_PORT, timeout=40):
            logger.info(f"å‰ç«¯å·²å°±ç»ª: http://localhost:{FRONTEND_PORT}")
        else:
            logger.warning("å‰ç«¯ç«¯å£æœªåœ¨é¢„æœŸæ—¶é—´å†…å°±ç»ªï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥")
    except Exception as e:
        logger.error(f"å¯åŠ¨å‰ç«¯å¤±è´¥: {e}")


def _stream_frontend_output(proc: subprocess.Popen):
    try:
        if proc.stdout is None:
            return
        for line in proc.stdout:
            if not line:
                break
            # é™å™ªï¼šä»…è®°å½•å…³é”®ä¿¡æ¯
            if any(key in line.lower() for key in ["ready in", "listening on", "error", "warn", "vite", "nuxt"]):
                logger.info(f"[frontend] {line.strip()}")
    except Exception:
        pass


def stop_frontend():
    global frontend_process
    if frontend_process is None:
        return
    if frontend_process.poll() is not None:
        frontend_process = None
        return
    logger.info("æ­£åœ¨åœæ­¢å‰ç«¯å¼€å‘æœåŠ¡å™¨...")
    try:
        if sys.platform == 'win32':
            try:
                frontend_process.send_signal(signal.CTRL_BREAK_EVENT)
            except Exception:
                frontend_process.terminate()
        else:
            import os as _os
            _os.killpg(_os.getpgid(frontend_process.pid), signal.SIGTERM)
        try:
            frontend_process.wait(timeout=10)
        except Exception:
            logger.warning("å‰ç«¯è¿›ç¨‹æœªæŒ‰æ—¶é€€å‡ºï¼Œå°è¯•å¼ºåˆ¶ç»“æŸ")
            if sys.platform == 'win32':
                frontend_process.kill()
            else:
                import os as _os
                _os.killpg(_os.getpgid(frontend_process.pid), signal.SIGKILL)
    finally:
        frontend_process = None

# ===================== ä¸»å‡½æ•° =====================
def run_flask():
    """è¿è¡ŒFlaskåº”ç”¨"""
    logger.info(f"FlaskæœåŠ¡å™¨å¯åŠ¨åœ¨: {LOCAL_IP}:{PORT}")
    app.run(host='0.0.0.0', port=PORT, debug=False, threaded=True)

def run_telegram_bot():
    """è¿è¡ŒTelegramæœºå™¨äºº"""
    global telegram_app, bot_info
    
    if not BOT_TOKEN:
        logger.error("è¯·å…ˆé…ç½®BOT_TOKENï¼")
        return
    
    async def start_bot():
        """å¼‚æ­¥å¯åŠ¨æœºå™¨äºº"""
        global telegram_app, bot_info
        
        try:
            telegram_app = Application.builder().token(BOT_TOKEN).build()
            
            # æ·»åŠ å¤„ç†å™¨
            telegram_app.add_handler(CommandHandler("start", start))
            telegram_app.add_handler(MessageHandler(filters.PHOTO & ~filters.ChatType.GROUP, handle_photo))
            telegram_app.add_handler(MessageHandler(filters.Document.IMAGE & ~filters.ChatType.GROUP, handle_photo))
            
            # ç¾¤ç»„å›¾ç‰‡å¤„ç†å™¨ï¼ˆä»…åœ¨å­˜å‚¨ç¾¤ç»„ä¸­ç”Ÿæ•ˆï¼‰
            if ENABLE_GROUP_UPLOAD:
                # ç¾¤ç»„ä¸­çš„å›¾ç‰‡
                telegram_app.add_handler(MessageHandler(
                    filters.PHOTO & filters.Chat(STORAGE_CHAT_ID),
                    handle_group_photo
                ))
                # ç¾¤ç»„ä¸­çš„å›¾ç‰‡æ–‡æ¡£
                telegram_app.add_handler(MessageHandler(
                    filters.Document.IMAGE & filters.Chat(STORAGE_CHAT_ID),
                    handle_group_photo
                ))
            
            logger.info("Telegramæœºå™¨äººå¯åŠ¨ä¸­...")
            
            # è·å–æœºå™¨äººä¿¡æ¯
            bot_info = await telegram_app.bot.get_me()
            logger.info(f"æœºå™¨äººä¿¡æ¯: @{bot_info.username} (ID: {bot_info.id})")
            
            # å¯åŠ¨æœºå™¨äºº
            await telegram_app.initialize()
            await telegram_app.start()
            await telegram_app.updater.start_polling(drop_pending_updates=True)
            
            logger.info("Telegramæœºå™¨äººå·²æˆåŠŸå¯åŠ¨")
            
            # ä¿æŒè¿è¡Œ
            await asyncio.Event().wait()
            
        except Exception as e:
            logger.error(f"Telegramæœºå™¨äººå¯åŠ¨å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
        finally:
            if telegram_app:
                await telegram_app.stop()
    
    # ä½¿ç”¨ asyncio.run è¿è¡Œå¼‚æ­¥å‡½æ•°
    try:
        asyncio.run(start_bot())
    except KeyboardInterrupt:
        logger.info("Telegramæœºå™¨äººæ”¶åˆ°åœæ­¢ä¿¡å·")
    except Exception as e:
        logger.error(f"è¿è¡ŒTelegramæœºå™¨äººæ—¶å‘ç”Ÿé”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰å®ä¾‹åœ¨è¿è¡Œ
    if not acquire_lock():
        logger.error("ç¨‹åºå·²åœ¨è¿è¡Œä¸­ï¼Œè¯·å‹¿é‡å¤å¯åŠ¨")
        sys.exit(1)
    
    init_database()
    
    # å¯åŠ¨CDNç›‘æ§
    if CDN_ENABLED and CLOUDFLARE_CDN_DOMAIN and CDN_MONITOR_ENABLED:
        start_cdn_monitor()
    
    logger.info("å¯åŠ¨Telegramäº‘å›¾åºŠæœåŠ¡...")

    # æ£€æŸ¥å‰ç«¯é™æ€æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(STATIC_FOLDER):
        logger.warning("=" * 60)
        logger.warning("å‰ç«¯é™æ€æ–‡ä»¶æœªæ‰¾åˆ°ï¼")
        logger.warning("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤æ„å»ºå‰ç«¯ï¼š")
        logger.warning("  cd frontend && npm run generate")
        logger.warning("=" * 60)
    else:
        logger.info(f"å‰ç«¯é™æ€æ–‡ä»¶å·²å°±ç»ª: {STATIC_FOLDER}")

    flask_thread = threading.Thread(target=run_flask, daemon=True)
    flask_thread.start()

    # å‰ç«¯å·²å†…ç½®ï¼Œä¸å†éœ€è¦å•ç‹¬å¯åŠ¨å¼€å‘æœåŠ¡å™¨
    logger.info("å‰ç«¯å·²å†…ç½®åˆ°Flaskä¸­ï¼Œç»Ÿä¸€ç«¯å£æœåŠ¡")

    time.sleep(2)
    
    try:
        if BOT_TOKEN:
            run_telegram_bot()
        else:
            logger.warning("Telegramæœºå™¨äººæœªå¯åŠ¨ï¼Œè¯·é…ç½®Tokenåé‡å¯")
            try:
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                logger.info("æœåŠ¡å·²åœæ­¢")
    finally:
        stop_frontend()
        stop_cdn_monitor()
        release_lock()

if __name__ == '__main__':
    main()